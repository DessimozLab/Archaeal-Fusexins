{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "698f2e80-f29f-41b6-bd2c-dd3670786a3d",
   "metadata": {},
   "source": [
    "# Overview\n",
    "Gene trees for archaeal FsxAs are inferred by aligning sequences with MAFFT (under L-INS-I) algorithm and running IQTree. Cleaning up of MSAs with <name of the program here> is also done in order to test if these changes something. Aligned sequences are either full-length FsxA sequences or their corresponding ectodomain.\n",
    "Sequences are those send by Dr. Pablo Aguilar in excel format by mail communication, and following suggestion by him some minor modifications of the data is done (as well as eliminating a duplicated sequence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75ab9929-d6f4-4b4e-84f8-6d419fa034f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import pandas as pd\n",
    "\n",
    "# creating some important directories in order to allocate data (if they doesn't exist)\n",
    "allocate_dirs = ['../data/sequences', '../data/MSAs', '../data/MSAs/raw', '../data/MSAs/clean']\n",
    "for dir in allocate_dirs:\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7896c718-a076-4656-b3b9-079c54440f3d",
   "metadata": {},
   "source": [
    "## Loading ecological data, performing minor data filtering and saving FASTAs in R\n",
    "There seems to be some missing ectodomain sequences and complete sequences..., but indeed it was my problem when passing Excel into a machine-readble xlsx file, so solving it by performing some minor modifications with tidyverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e915c6-6e82-44f5-bfc7-2ab7662fc885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "702d8304-34a0-47fd-9311-2ccedad0db2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: ── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────────────────────────────────────────── tidyverse 1.3.1 ──\n",
      "\n",
      "R[write to console]: \u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.3     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.2     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.6\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.3     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.4.0     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n",
      "\n",
      "R[write to console]: ── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘magrittr’\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    set_names\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    extract\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘glue’\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    collapse\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "R[write to console]: -\n",
      "R[write to console]: \n",
      "R[write to console]: /\n",
      "                                                                              \n",
      "R[write to console]: \n"
     ]
    }
   ],
   "source": [
    "%%R \n",
    "\n",
    "library(tidyverse)\n",
    "library(magrittr)\n",
    "library(glue)\n",
    "library(readxl)\n",
    "library(bioseq)\n",
    "\n",
    "# loading ecological metadata\n",
    "ecological_data_columns = c('HEADER','scaffold ID_ORF','scaffold ID_ORF (SPADES)','CONFIDENCE','METAGENOMICS PROJECT',\n",
    "                               'TAXA','scaffold length','COMPLETE SEQUENCE','LENGTH','SIGNAL PEPTIDE?','TMs','ECTODOMAIN',\n",
    "                               'ECTO LENGTH','C','Num CYS','ECTO Isoelectric point','COMMENTS','BIOSAMPLE','MG NAME',\n",
    "                               'HABITAT_Detailed','Temperature_Detailed','elev mts','collec DATE','HABITAT','AUTHORS',\n",
    "                               'CONTACT','PAPER DOI','ISOLATION','SOLID','AQUEOUS','SALT?','pH','T_Classified',\n",
    "                               'ALT_DEPT (mts)','FILTER FRACTION','O2')\n",
    "\n",
    "ecological_metadata_table = readxl::read_xlsx('../data/metadata/modified_FsxAs-Kosher-Taxo-Abr-2021.xlsx',\n",
    "                                            col_names = ecological_data_columns, \n",
    "                                            skip = 1)\n",
    "        \n",
    "#ecological_data.tibble %>% dplyr::filter(is.na(ECTODOMAIN)) \n",
    "ecological_metadata_table %<>% dplyr::filter(!is.na(`COMPLETE SEQUENCE`) & !is.na(`ECTODOMAIN`)) \n",
    "\n",
    "# saving this data in TSV format in order to avoid problems when reading\n",
    "ecological_metadata_table %>% readr::write_tsv(., '../data/metadata/modified_FsxAs-Kosher-Taxo-Abr-2021.tsv')\n",
    "    \n",
    "# creating FASTAs with bioseq\n",
    "tibble(label = ecological_metadata_table$HEADER,\n",
    "       sequence = ecological_metadata_table$`COMPLETE SEQUENCE`) %>%\n",
    "    deframe() %>%\n",
    "    as_aa() %>%\n",
    "    bioseq::write_fasta(., '../data/sequences/FsxA_full_length.faa')\n",
    "            \n",
    "tibble(label = ecological_metadata_table$HEADER,\n",
    "       sequence = ecological_metadata_table$`ECTODOMAIN`) %>%\n",
    "    deframe() %>%\n",
    "    as_aa() %>%\n",
    "    bioseq::write_fasta(., '../data/sequences/FsxA_ectodomains.faa')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8368f7bc-a15f-42f4-b5f3-3d5424cce5f9",
   "metadata": {},
   "source": [
    "**Notes of importance**: \n",
    "- should check number of sequences that indeed present a COMPLETE SEQUENCE and ECTODOMAIN, and see if they are the same as mentioned by Martin by email-communication.\n",
    "- tried to perform saving of FASTAs with Bio.SeqIO in python but got a weird error, maybe related with other stuff... polishing will be done there, but that's the reason why procesing of FASTAs is done in two different parts of the script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed170d6-7cfa-439e-a85b-003f788aa66b",
   "metadata": {},
   "source": [
    "**Note**: checked the number of sequences in both FASTAs and it is OK (94 sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905a67b9-732c-472e-bd69-c7c451e2480d",
   "metadata": {},
   "source": [
    "## Running MSAs and MSA trimming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8185b91d-d86f-47ae-9abe-d66dfdda4413",
   "metadata": {},
   "source": [
    "## Tree only with FsxA ectodomains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0ab0e8-4ac4-4c77-bd3e-88b198d3f294",
   "metadata": {},
   "source": [
    "### MAFFT (L-INS-I algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9385f13-6d9d-4479-b6f8-5e0a2b3a6194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('FsxA_full_length', '../data/sequences/FsxA_full_length.faa'),\n",
       " ('FsxA_ectodomains', '../data/sequences/FsxA_ectodomains.faa'),\n",
       " ('hap2.P.HU', '../data/sequences/hap2.P.HU.faa')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running MSA with MAFFT under L-INS-I algorithm\n",
    "fasta_sets = [(fasta_file.split('/')[3].replace('.faa', ''),\n",
    "              fasta_file) for fasta_file in glob.glob('../data/sequences/*faa')]\n",
    "fasta_sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ceaab95-082a-4773-9bd9-a0d26979780f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fasta_set in fasta_sets:\n",
    "  # depacking variables\n",
    "  tag, fasta_file = fasta_set\n",
    "  msa_output = '../data/MSAs/raw/{0}.msa'.format(tag)\n",
    "  if not os.path.exists(msa_output):\n",
    "    out_file = open(msa_output, 'w') \n",
    "    mafft_command = 'mafft --maxiterate 1000 --localpair {0}'.format(fasta_file).split(' ')\n",
    "    subprocess.run(mafft_command, stdout = out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f62f097-ac0d-4207-b58d-7eb3ab7934fc",
   "metadata": {},
   "source": [
    "## Running IQTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cb5f7cd-f636-40cc-b972-7474b0e01e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running IQTree with model selection and tree inference by maximum-likelihood, under 1000 ultrafast-bootstrap replicates\n",
    "for fasta_set in fasta_sets:\n",
    "  # depacking variables\n",
    "  tag, fasta_file = fasta_set\n",
    "  # creating directories to allocate results\n",
    "  if not os.path.exists('../data/trees/infered_by_mauricio'):\n",
    "        os.mkdir('../data/trees/infered_by_mauricio')\n",
    "  family_iqtree_dir = '../data/trees/infered_by_mauricio/{0}'.format(tag)\n",
    "  msa_output = '../data/MSAs/raw/{0}.msa'.format(tag)\n",
    "  if not os.path.exists(family_iqtree_dir):\n",
    "        # create dir and run IQTree\n",
    "        os.mkdir(family_iqtree_dir)\n",
    "        # run IQTree\n",
    "        iqtree_cmd = 'iqtree2 -s {0} -m TEST --threads-max 15 -alrt 1000 -B 1000 -pre {2}/{1}'.format(msa_output, tag, family_iqtree_dir).split(' ')\n",
    "        subprocess.run(iqtree_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806c6564-1ab0-4fee-83f4-fd710d8af5ca",
   "metadata": {},
   "source": [
    "## Tree with FsxAs + HAP2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908a8080-9370-4b2d-9b81-0a5eb7fea96b",
   "metadata": {},
   "source": [
    "### Extracting HAP2 ectodomains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be7eabfc-ce1c-4bc0-a71e-241223b311fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# copy HAP2 sequences\n",
    "if not os.path.exists('../data/sequences/hap2.P.HU.faa'):\n",
    "    shutil.copy(src = '/media4/eletor/genomas/hap2.P.HU.faa', dst = '../data/sequences/hap2.P.HU.faa')\n",
    "    \n",
    "# perform search of FsxA ectodomain HMM against sequences with hmmsearch\n",
    "# create directories to allocate results\n",
    "hap2_dirs = ['../results/extracting_HAP2_ectodomains', '../results/extracting_HAP2_ectodomains/hmmsearchout', '../results/extracting_HAP2_ectodomains/sequences']\n",
    "for dir in hap2_dirs:\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "\n",
    "# copy FsxA ectodomain HMM and perform hmmsearch\n",
    "if not os.path.exists('../data/sequences/fsx.ectos.hmm'):\n",
    "    shutil.copy(src = '/media4/eletor/FsxA/Halobacteria/HMMfsxa/fsx.ectos.hmm', dst = '../data/sequences/fsx.ectos.hmm')\n",
    "    \n",
    "hmmsearchout = '../results/extracting_HAP2_ectodomains/hmmsearchout/fsxA_ectodomain_vs_HAP2s.hmmsearchout'\n",
    "hmmsearchtblout = '../results/extracting_HAP2_ectodomains/hmmsearchout/fsxA_ectodomain_vs_HAP2s.tblout'\n",
    "hmmsearchdomtblout = '../results/extracting_HAP2_ectodomains/hmmsearchout/fsxA_ectodomain_vs_HAP2s.domtblout'\n",
    "if not os.path.exists(hmmsearchout):\n",
    "  hmmsearch_cmd = 'hmmsearch -o {0} --tblout {1} --domtblout {2} --cpu 3 ../data/sequences/fsx.ectos.hmm ../data/sequences/hap2.P.HU.faa'.format(hmmsearchout, hmmsearchtblout, hmmsearchdomtblout).split(' ')\n",
    "  subprocess.run(hmmsearch_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da546ab-7923-4527-abf8-4aa83817cdb2",
   "metadata": {},
   "source": [
    "Parsing hmmsearch outfiles with R's library rhmmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ff66945-bb50-4467-8d01-8ce523028cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1977b083-9364-431c-a028-3cd2f1e55af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db39f4f6-cf8b-4a71-9269-4d7b6f2ad634",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -o fsx_ectodomains_vs_HAP2s_filtered_table\n",
    "# script made to parse hmmsearch results of homologous groups against ORFs\n",
    "# loading libraries\n",
    "library(rhmmer)\n",
    "library(tidyverse)\n",
    "library(magrittr)\n",
    "library(glue)\n",
    "\n",
    "# create vector with column names of hmmsearch output\n",
    "domtblouts_colnames = c('target_name', 't_accession', 'tlen', 'query_name', 'q_accession', 'qlen',\n",
    "                    'fullseq_evalue', 'fullseq_score', 'fullseq_bias', 'num_of_domain', 'total_hit_domains', \n",
    "                    'c-evalue', 'i-evalue', 'hmm_score', 'hmm_bias', 'hmm_coord_from', 'hmm_coord_to', 'ali_coord_from',\n",
    "                    'ali_coord_to', 'env_coord_from', 'env_coord_to', 'acc', 'description_of_target')\n",
    "\n",
    "# see how many hits has each homologous group\n",
    "filtered_hits.tibble = list.files('../results/extracting_HAP2_ectodomains/hmmsearchout', pattern = '.domtblout', full.names=T) %>%\n",
    "  as.list() %>%\n",
    "  purrr::map_dfr(., ~{\n",
    "    # load results\n",
    "    current_domtblout.tibble = rhmmer::read_domtblout(file = .x)\n",
    "    # rename columns\n",
    "    colnames(current_domtblout.tibble) = domtblouts_colnames\n",
    "    # filtering results\n",
    "    current_domtblout.tibble %>%\n",
    "      rowwise() %>%\n",
    "      # creating column with alignment length and getting qcov\n",
    "      dplyr::mutate(aln_length = abs(ali_coord_to - ali_coord_from),\n",
    "                    qcov = aln_length/qlen) %>%\n",
    "      # query coverage must be at least 70%\n",
    "      dplyr::filter(qcov >= 0.7) %>%\n",
    "      # global sequence e-value must be at most 1e-15\n",
    "      dplyr::filter(fullseq_evalue <= 1e-15)\n",
    "                 })\n",
    "\n",
    "# saving table\n",
    "filtered_hits.tibble %>% readr::write_tsv(., '../results/extracting_HAP2_ectodomains/hmmsearchout/fsx_ectodomain_vs_HAP2s_hmmsearch_filtered.tsv')\n",
    "        \n",
    "# create variable to export to python \n",
    "fsx_ectodomains_vs_HAP2s_filtered_table = filtered_hits.tibble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdf66144-c5b3-42ac-9d98-2d94526d7401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_name</th>\n",
       "      <th>t_accession</th>\n",
       "      <th>tlen</th>\n",
       "      <th>query_name</th>\n",
       "      <th>q_accession</th>\n",
       "      <th>qlen</th>\n",
       "      <th>fullseq_evalue</th>\n",
       "      <th>fullseq_score</th>\n",
       "      <th>fullseq_bias</th>\n",
       "      <th>num_of_domain</th>\n",
       "      <th>...</th>\n",
       "      <th>hmm_coord_from</th>\n",
       "      <th>hmm_coord_to</th>\n",
       "      <th>ali_coord_from</th>\n",
       "      <th>ali_coord_to</th>\n",
       "      <th>env_coord_from</th>\n",
       "      <th>env_coord_to</th>\n",
       "      <th>acc</th>\n",
       "      <th>description_of_target</th>\n",
       "      <th>aln_length</th>\n",
       "      <th>qcov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cper_4312</td>\n",
       "      <td>-</td>\n",
       "      <td>981</td>\n",
       "      <td>fsx.ectos.mafft</td>\n",
       "      <td>-</td>\n",
       "      <td>484</td>\n",
       "      <td>7.200000e-68</td>\n",
       "      <td>223.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>446</td>\n",
       "      <td>25</td>\n",
       "      <td>521</td>\n",
       "      <td>21</td>\n",
       "      <td>587</td>\n",
       "      <td>0.86</td>\n",
       "      <td>None</td>\n",
       "      <td>496</td>\n",
       "      <td>1.024793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000313135.1</td>\n",
       "      <td>-</td>\n",
       "      <td>927</td>\n",
       "      <td>fsx.ectos.mafft</td>\n",
       "      <td>-</td>\n",
       "      <td>484</td>\n",
       "      <td>3.400000e-62</td>\n",
       "      <td>204.4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>470</td>\n",
       "      <td>34</td>\n",
       "      <td>580</td>\n",
       "      <td>29</td>\n",
       "      <td>604</td>\n",
       "      <td>0.81</td>\n",
       "      <td>ELR19439.1</td>\n",
       "      <td>546</td>\n",
       "      <td>1.128099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sarc_20979</td>\n",
       "      <td>-</td>\n",
       "      <td>945</td>\n",
       "      <td>fsx.ectos.mafft</td>\n",
       "      <td>-</td>\n",
       "      <td>484</td>\n",
       "      <td>4.300000e-61</td>\n",
       "      <td>200.8</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>429</td>\n",
       "      <td>34</td>\n",
       "      <td>528</td>\n",
       "      <td>27</td>\n",
       "      <td>542</td>\n",
       "      <td>0.86</td>\n",
       "      <td>None</td>\n",
       "      <td>494</td>\n",
       "      <td>1.020661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cfra_3504</td>\n",
       "      <td>-</td>\n",
       "      <td>1093</td>\n",
       "      <td>fsx.ectos.mafft</td>\n",
       "      <td>-</td>\n",
       "      <td>484</td>\n",
       "      <td>9.100000e-57</td>\n",
       "      <td>186.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>424</td>\n",
       "      <td>7</td>\n",
       "      <td>473</td>\n",
       "      <td>2</td>\n",
       "      <td>489</td>\n",
       "      <td>0.84</td>\n",
       "      <td>None</td>\n",
       "      <td>466</td>\n",
       "      <td>0.962810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>003719475.1</td>\n",
       "      <td>-</td>\n",
       "      <td>585</td>\n",
       "      <td>fsx.ectos.mafft</td>\n",
       "      <td>-</td>\n",
       "      <td>484</td>\n",
       "      <td>2.100000e-56</td>\n",
       "      <td>185.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>481</td>\n",
       "      <td>24</td>\n",
       "      <td>548</td>\n",
       "      <td>20</td>\n",
       "      <td>552</td>\n",
       "      <td>0.81</td>\n",
       "      <td>RNF04482.1</td>\n",
       "      <td>524</td>\n",
       "      <td>1.082645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_name t_accession  tlen       query_name q_accession  qlen  \\\n",
       "1    Cper_4312           -   981  fsx.ectos.mafft           -   484   \n",
       "2  000313135.1           -   927  fsx.ectos.mafft           -   484   \n",
       "3   Sarc_20979           -   945  fsx.ectos.mafft           -   484   \n",
       "4    Cfra_3504           -  1093  fsx.ectos.mafft           -   484   \n",
       "5  003719475.1           -   585  fsx.ectos.mafft           -   484   \n",
       "\n",
       "   fullseq_evalue  fullseq_score  fullseq_bias  num_of_domain  ...  \\\n",
       "1    7.200000e-68          223.2          13.7              1  ...   \n",
       "2    3.400000e-62          204.4          10.6              1  ...   \n",
       "3    4.300000e-61          200.8          10.4              1  ...   \n",
       "4    9.100000e-57          186.5           1.1              1  ...   \n",
       "5    2.100000e-56          185.4           0.0              1  ...   \n",
       "\n",
       "   hmm_coord_from  hmm_coord_to  ali_coord_from  ali_coord_to  env_coord_from  \\\n",
       "1               8           446              25           521              21   \n",
       "2               6           470              34           580              29   \n",
       "3               9           429              34           528              27   \n",
       "4              19           424               7           473               2   \n",
       "5               7           481              24           548              20   \n",
       "\n",
       "   env_coord_to   acc  description_of_target  aln_length      qcov  \n",
       "1           587  0.86                   None         496  1.024793  \n",
       "2           604  0.81             ELR19439.1         546  1.128099  \n",
       "3           542  0.86                   None         494  1.020661  \n",
       "4           489  0.84                   None         466  0.962810  \n",
       "5           552  0.81             RNF04482.1         524  1.082645  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse hits and extract matching sequences from HAP2\n",
    "fsx_ectodomains_vs_HAP2s_filtered_table.head() # important: in this table ali_coord_from and ali_coord_to refer to coordinates in subject sequence,\n",
    "                                        # and hmm_coord_from and hmm_coord_to refer to positions in the Fsx ectodomain HMM\n",
    "# save in files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb0548a-803c-406a-a4b4-d380ce30eb3b",
   "metadata": {},
   "source": [
    "### Selection HAP2 sequences to be used\n",
    " - Going to include just 3 or 4 seqs. In this section I retrieve from NCBI some taxonomical features in order to decide... (**didnt work, so taking 5 at random**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3e47353-873d-4b9a-8459-96295e3ad0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to do this by API calls\n",
    "import requests\n",
    "# import time\n",
    "# from requests.adapters import HTTPAdapter\n",
    "# #response = requests.get('https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=protein&term={0}'.format('SBT79210.1'))\n",
    "# \n",
    "# page = ''\n",
    "# while page == '':\n",
    "#     try:\n",
    "#         page = requests.get('https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=protein&term={0}'.format('SBT79210.1'), HTTPAdapter(max_retries=1))\n",
    "#         break\n",
    "#     except:\n",
    "#         print(\"Connection refused by the server..\")\n",
    "#         print(\"Let me sleep for 5 seconds\")\n",
    "#         print(\"ZZzzzz...\")\n",
    "#         time.sleep(5)\n",
    "#         print(\"Was a nice sleep, now let me continue...\")\n",
    "#         continue\n",
    "# response_json = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8b5be91-4a96-4108-ad32-c6e08f8dfc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Biopython entrez tools\n",
    "from Bio import Entrez\n",
    "\n",
    "# #help(Entrez.esummary)\n",
    "# Entrez.email = 'mauricio.langleib@gmail.com'\n",
    "# #handle = Entrez.esearch(db=\"Taxonomy\", term=\"Cypripedioideae\")\n",
    "# #record = Entrez.read(handle)\n",
    "# #record[\"IdList\"]\n",
    "# #record[\"IdList\"][0]\n",
    "# #\n",
    "# #handle = Entrez.efetch(db=\"Taxonomy\", id=\"158330\", retmode=\"xml\")\n",
    "# #records = Entrez.read(handle)\n",
    "# #\n",
    "# #records[0]\n",
    "# \n",
    "# handle = Entrez.esearch(db=\"protein\", term=\"SBT79210.1\", retmode='xml')\n",
    "# record = Entrez.read(handle)\n",
    "# record[\"IdList\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a448245-2e93-459e-aaf8-288f33ac219c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58790b36-93cf-49d3-950f-40d967cbb96c",
   "metadata": {},
   "source": [
    "### Checking length of Fsx ectodomains\n",
    "Just to check that the obtained result makes sense..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "088fa222-6b0f-4b08-a07c-09a5e225fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "# loading HAP2 sequences and extracting HAP2 ectodomains\n",
    "# create variable to allocate ectodomain sequences\n",
    "hap2_ectodomains = []\n",
    "# create dict with HAP2 sequences\n",
    "hap2_seqs_dict = {record.id: record for record in SeqIO.parse('../data/sequences/hap2.P.HU.faa', 'fasta')}\n",
    "\n",
    "# iterate over hit table and extract domains\n",
    "for index, row in fsx_ectodomains_vs_HAP2s_filtered_table.iterrows():\n",
    "    # get sequence id, and HMM-to-seq alignment\n",
    "    sequence_id = row['target_name']\n",
    "    aln_start = row['ali_coord_from']\n",
    "    aln_stop = row['ali_coord_to']\n",
    "    # get sequence record\n",
    "    seq_record = hap2_seqs_dict[sequence_id]\n",
    "    # subset to alignment coordinates and add to description de \"ECTODOMAIN\" word\n",
    "    seq_record_ectodomain = seq_record[aln_start:aln_stop]\n",
    "    seq_record_ectodomain.description = seq_record_ectodomain.description + '_ECTODOMAIN'\n",
    "    # append to ectodomains list\n",
    "    hap2_ectodomains.append(seq_record_ectodomain)\n",
    "    \n",
    "# save HAP2 ectodomains to FASTA file\n",
    "with open('../results/extracting_HAP2_ectodomains/sequences/HAP2_ectodomains.faa', 'w') as handle_fasta:\n",
    "    SeqIO.write(hap2_ectodomains, handle_fasta,'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c80649b-287c-41e9-8f2f-70ab64e5a1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting five HAP2 seqs at random, setting seed previously in order to get reproducible results if script runs again\n",
    "import random\n",
    "random.seed(22)\n",
    "hap2_selected_ectodomains = random.sample(hap2_ectodomains, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55251a18-603e-44d7-b9ea-56186a50d35c",
   "metadata": {},
   "source": [
    "### Join HAP2 ectodomains with FsxA ectodmains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3bd5bbf9-8cd9-4f2f-9015-04f6bdca4942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending to FsxA ectodomain sequences\n",
    "# loading FsxA ectodomains\n",
    "fsxa_ectodomains = [record for record in SeqIO.parse('../data/sequences/FsxA_ectodomains.faa', 'fasta')]\n",
    "fsx_complete_set = fsxa_ectodomains + hap2_selected_ectodomains\n",
    "\n",
    "# saving \n",
    "with open('../data/sequences/fsxA_and_hap2_ectodomains.faa', 'w') as handle_fasta:\n",
    "    SeqIO.write(fsx_complete_set, handle_fasta, 'fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdf5d7c-453a-450c-adf1-89a15eb17259",
   "metadata": {},
   "source": [
    "### Infer MSA and phylogeny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3da59aa5-1f2e-4361-83ca-4023d8deb4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running MSA with MAFFT under L-INS-I algorithm\n",
    "fasta_sets = [(fasta_file.split('/')[3].replace('.faa', ''),\n",
    "              fasta_file) for fasta_file in glob.glob('../data/sequences/*faa')]\n",
    "\n",
    "for fasta_set in fasta_sets:\n",
    "  # depacking variables\n",
    "  tag, fasta_file = fasta_set\n",
    "  msa_output = '../data/MSAs/raw/{0}.msa'.format(tag)\n",
    "  if not os.path.exists(msa_output):\n",
    "    out_file = open(msa_output, 'w') \n",
    "    mafft_command = 'mafft --maxiterate 1000 --localpair {0}'.format(fasta_file).split(' ')\n",
    "    subprocess.run(mafft_command, stdout = out_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "643c3530-1755-4c45-be33-d0eb9a2a5d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running IQTree with model selection and tree inference by maximum-likelihood, under 1000 ultrafast-bootstrap replicates\n",
    "for fasta_set in fasta_sets:\n",
    "  # depacking variables\n",
    "  tag, fasta_file = fasta_set\n",
    "  # creating directories to allocate results\n",
    "  if not os.path.exists('../data/trees/infered_by_mauricio'):\n",
    "        os.mkdir('../data/trees/infered_by_mauricio')\n",
    "  family_iqtree_dir = '../data/trees/infered_by_mauricio/{0}'.format(tag)\n",
    "  msa_output = '../data/MSAs/raw/{0}.msa'.format(tag)\n",
    "  if not os.path.exists(family_iqtree_dir):\n",
    "        # create dir and run IQTree\n",
    "        os.mkdir(family_iqtree_dir)\n",
    "        # run IQTree\n",
    "        iqtree_cmd = 'iqtree2 -s {0} -m TEST --threads-max 15 -alrt 1000 -B 1000 -pre {2}/{1}'.format(msa_output, tag, family_iqtree_dir).split(' ')\n",
    "        subprocess.run(iqtree_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea4fef4-de61-4b7a-8ca2-65d527c818b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
