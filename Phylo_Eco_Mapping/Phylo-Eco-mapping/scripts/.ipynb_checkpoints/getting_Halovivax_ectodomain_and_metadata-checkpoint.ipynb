{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad642b08-627e-43c6-8a06-ab2deea1ee51",
   "metadata": {},
   "source": [
    "# Overview\n",
    "Previous results were done without the Halovivax sp. KZCA124 data. Updating to incorporate it.\n",
    "In this notebook:\n",
    "- I get the FsxA of Halovivax from the inferred homolog groups previously infered.\n",
    "- Infer the position of the ectodomain for it (by means of an hmmsearch employing an Fsx ectodomain HMM as query against the sequence).\n",
    "- Extract the ectodomain and join it to data send by Martin.\n",
    "- Infer a new FsxA-ectodomain phylogeny\n",
    "- Get metadata for the genome from NCBI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2355b3-84c8-4e27-815b-0bf70cf9398d",
   "metadata": {},
   "source": [
    "# Getting Halovivax FsxA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c755fbb-a93f-4036-9b54-73b466de4f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "# define auxiliary function\n",
    "def create_dir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "        \n",
    "# create target directories\n",
    "target_dirs = ['../data/new_subset/halovivax_seqs',\n",
    "               '../data/new_subset/halovivax_seqs/hmmsearch_results',\n",
    "               '../data/new_subset/including_halovivax']\n",
    "\n",
    "[create_dir(dir) for dir in target_dirs]\n",
    "\n",
    "# load table for sequences of archaea, ORF annotation and so on and so on\n",
    "orf_annot_table = pd.read_csv('../../analysis_mobile_elements_with_MAGs_and_Halovivax/results/MEs_annotated_features_vs_predicted_orfs_BRHs.tsv', sep = '\\t')\n",
    "\n",
    "# get sequences of the CG_3 cluster (i.e. FsxAs)\n",
    "fsxa_seqs = [record for record in SeqIO.parse('../../analysis_mobile_elements_with_MAGs_and_Halovivax/results/trying_to_catch_homologs/results/connected_groups_filtered/fastas/protein/CG_3.faa', 'fasta')]\n",
    "fsxa_ids = [record.id for record in fsxa_seqs]\n",
    "\n",
    "# get table with taxa info\n",
    "taxa_info = pd.read_csv('../../analysis_mobile_elements_with_MAGs_and_Halovivax/data/genomes_and_taxonomy.csv')\n",
    "\n",
    "# get Halovivax ID\n",
    "halovivax_id = taxa_info.query(\"`Taxonomy`.str.contains('Halovivax')\")['Genome_id'].to_list()[0]\n",
    "\n",
    "# identify that of Halovivax and save it\n",
    "halovivax_fsxA_id = orf_annot_table.query(\"`subject_id` in @fsxa_ids and `subject_id`.str.contains('NZ_CP071597.1')\")['subject_id'].to_list()[0]\n",
    "halovivax_fsxA_name = orf_annot_table.query(\"`subject_id` in @fsxa_ids and `subject_id`.str.contains('NZ_CP071597.1')\")['query_id'].to_list()[0]\n",
    "\n",
    "halovivax_fsxA_record = [record for record in fsxa_seqs if record.id == halovivax_fsxA_id]\n",
    "\n",
    "# rename and save\n",
    "halovivax_fsxA_record[0].id = halovivax_fsxA_name\n",
    "halovivax_fsxA_record[0].name = halovivax_fsxA_name\n",
    "halovivax_fsxA_record[0]. description = ''\n",
    "\n",
    "if not os.path.exists('../data/new_subset/halovivax_seqs/halovivax_fsxA.faa'):\n",
    "    with open('../data/new_subset/halovivax_seqs/halovivax_fsxA.faa', 'w') as handle_fasta:\n",
    "        SeqIO.write(halovivax_fsxA_record, handle_fasta, 'fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c3d676-1f12-439e-9cb0-082c2e6cb850",
   "metadata": {},
   "source": [
    "# Extract Halovivax FsxA ectodomain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3fd31460-65f2-4563-821a-c9cc515f82d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform hmmsearch to get ectodomain\n",
    "if not os.path.exists('../data/new_subset/halovivax_seqs/hmmsearch_results/fsx_ectodomain_vs_halovivax_fsxA.domtblout'):\n",
    "    hmmsearch_cmd = 'hmmsearch -o ../data/new_subset/halovivax_seqs/hmmsearch_results/fsx_ectodomain_vs_halovivax_fsxA.hmmsearchout --tblout ../data/new_subset/halovivax_seqs/hmmsearch_results/fsx_ectodomain_vs_halovivax_fsxA.tsv --domtblout ../data/new_subset/halovivax_seqs/hmmsearch_results/fsx_ectodomain_vs_halovivax_fsxA.domtblout --pfamtblout ../data/new_subset/halovivax_seqs/hmmsearch_results/fsx_ectodomain_vs_halovivax_fsxA.pfamtblout --cpu 10 ../../pR1SE/results/hmmer_search/data/fsx.ectos.hmm ../data/new_subset/halovivax_seqs/halovivax_fsxA.faa'.split(' ')\n",
    "    subprocess.run(hmmsearch_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "424e7c08-976b-43d0-8c96-5b0295504876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# hmmsearch :: search profile(s) against a sequence database\n",
      "# HMMER 3.1b2 (February 2015); http://hmmer.org/\n",
      "# Copyright (C) 2015 Howard Hughes Medical Institute.\n",
      "# Freely distributed under the GNU General Public License (GPLv3).\n",
      "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "# query HMM file:                  ../../pR1SE/results/hmmer_search/data/fsx.ectos.hmm\n",
      "# target sequence database:        ../data/new_subset/halovivax_seqs/halovivax_fsxA.faa\n",
      "# output directed to file:         ../data/new_subset/halovivax_seqs/hmmsearch_results/fsx_ectodomain_vs_halovivax_fsxA.hmmsearchout\n",
      "# per-seq hits tabular output:     ../data/new_subset/halovivax_seqs/hmmsearch_results/fsx_ectodomain_vs_halovivax_fsxA.tsv\n",
      "# per-dom hits tabular output:     ../data/new_subset/halovivax_seqs/hmmsearch_results/fsx_ectodomain_vs_halovivax_fsxA.domtblout\n",
      "# pfam-style tabular hit output:   ../data/new_subset/halovivax_seqs/hmmsearch_results/fsx_ectodomain_vs_halovivax_fsxA.pfamtblout\n",
      "# number of worker threads:        10\n",
      "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "Query:       fsx.ectos.mafft  [M=484]\n",
      "Scores for complete sequences (score includes all domains):\n",
      "   --- full sequence ---   --- best 1 domain ---    -#dom-\n",
      "    E-value  score  bias    E-value  score  bias    exp  N  Sequence                                   Description\n",
      "    ------- ------ -----    ------- ------ -----   ---- --  --------                                   -----------\n",
      "    4.4e-82  262.5   3.7    5.6e-82  262.2   3.7    1.0  1  lcl|NZ_CP071597.1_prot_WP_207587115.1_2894  \n",
      "\n",
      "\n",
      "Domain annotation for each sequence (and alignments):\n",
      ">> lcl|NZ_CP071597.1_prot_WP_207587115.1_2894  \n",
      "   #    score  bias  c-Evalue  i-Evalue hmmfrom  hmm to    alifrom  ali to    envfrom  env to     acc\n",
      " ---   ------ ----- --------- --------- ------- -------    ------- -------    ------- -------    ----\n",
      "   1 !  262.2   3.7   5.6e-82   5.6e-82       4     468 ..      24     501 ..      21     533 .. 0.85\n",
      "\n",
      "  Alignments for each domain:\n",
      "  == domain 1  score: 262.2 bits;  conditional E-value: 5.6e-82\n",
      "                             fsx.ectos.mafft   4 ftvlsvsqadlesc..elcgqkwvvtvtvsgggqslegdidkselndslgdkaekdlsieitkskqs 68 \n",
      "                                                 + v+sv+++++ s+  +++g+++v+ +  +  ++ +++++++++l++++++++++dlsi++  +++ \n",
      "  lcl|NZ_CP071597.1_prot_WP_207587115.1_2894  24 AAVTSVDSIQFDSNskFFSGEVFVIQYISNFDTDRIDVVLSSNDLEQAADGEVDQDLSIDVVQQDTA 90 \n",
      "                                                 6799***********888************************************************* PP\n",
      "\n",
      "                             fsx.ectos.mafft  69 leYpitvnynpreiy.kveyse..gsvgs..d.aedpsCesnesqg.cg.sleqvvghgttdpvsvs 127\n",
      "                                                 + Y i  + + ++   ++e+++   s+++  d +  ++C++ +  g     +e+v++++      v+\n",
      "  lcl|NZ_CP071597.1_prot_WP_207587115.1_2894  91 ALYSI--SPSGEPRLgNLELTTaeKSTFEelDrWAWDTCYDINGDGgKEyAYESVLTWSG----TVY 151\n",
      "                                                 *****..55556666677777777666668999******776644445557888888774....368 PP\n",
      "\n",
      "                             fsx.ectos.mafft 128 tahClrqddl.gyvgeigsprihfdievtlta.gggsesktLsps.sgsgs.gsigddvkvqwlGnl 190\n",
      "                                                   +C r++   g vg i   r  f++e+ ++a g++ +++tLs++ +g g  ++igd vkv+w+Gnl\n",
      "  lcl|NZ_CP071597.1_prot_WP_207587115.1_2894 152 RGYCARENGFyGPVGRITKDREVFTTEWRVEAsGESAQTATLSNGdTGRGVvSDIGDHVKVRWDGNL 218\n",
      "                                                 99***9888779********************98789*******87555557999999********* PP\n",
      "\n",
      "                             fsx.ectos.mafft 191 atgescapdlsnkylPsypd..sgnwklvskseyssysaryqslssclgngrcsssevgsclnn.yn 254\n",
      "                                                 +tge+ ap    +y + + +  ++ w+++++++y ++ ++  +l+   ++ r++ ++ +++l+n ++\n",
      "  lcl|NZ_CP071597.1_prot_WP_207587115.1_2894 219 DTGEE-APPADKEY-ALHGNqfEDGWRIIDRGRYADWRQHVRDLDTAYEQWRDG-DRSRDYLQNqLD 282\n",
      "                                                 *****.56344455.5666556689**********9999888887777666544.445555544345 PP\n",
      "\n",
      "                             fsx.ectos.mafft 255 sdldkllsdktsatyfvs.rggsifkgstsfqegklvveldsriqyPtftlyvdA.dwvgiitpvge 319\n",
      "                                                 +  +++++++t     +s    s++ +s++ ++g+l++e+d+++ yP ft+yvd  ++v++ +pvg \n",
      "  lcl|NZ_CP071597.1_prot_WP_207587115.1_2894 283 TATEQAAAEYT-----GSpL-TSAETVSSTYTDGQLRLEMDTDLAYPSFTVYVDGaEYVSVSKPVGR 343\n",
      "                                                 55555555544.....4432.23344677888*********************9559********** PP\n",
      "\n",
      "                             fsx.ectos.mafft 320 pkItsasstsfksgdtgtievtvkNvGdergsfsvsv.eCssgiqsaspaqsislapgetktltfdl 385\n",
      "                                                 p+Its++ ++f + dtg+++ tv+NvGd++gsf  ++ +Cs+g++  s++ +  ++pg++ t++f++\n",
      "  lcl|NZ_CP071597.1_prot_WP_207587115.1_2894 344 PEITSTNGDEFGELDTGYVTGTVRNVGDGEGSFAGRLtSCSDGFSFDSTQRTQRVDPGASVTYEFPV 410\n",
      "                                                 *************************************99*******99999**************** PP\n",
      "\n",
      "                             fsx.ectos.mafft 386 sgst..dqeeitgtCtvtvedanspeksdsktvsvdvtpqqvCtpgekscsd.....keikkCnsdG 445\n",
      "                                                 s+++  dq+e+ g+Ct++v+d+ s ++ d  t+ v+  ++++C+pge++ +      ++i++C++dG\n",
      "  lcl|NZ_CP071597.1_prot_WP_207587115.1_2894 411 SFTStgDQDEVGGSCTIEVTDTGS-GERDFATAAVTGVQENECSPGERFSKVasggqHVIYQCSEDG 476\n",
      "                                                 **55467777*************7.9*********************9988899************* PP\n",
      "\n",
      "                             fsx.ectos.mafft 446 styelvetCesg..ceykegkakCk 468\n",
      "                                                  t+++ve Ce+g  ++  +++ +C+\n",
      "  lcl|NZ_CP071597.1_prot_WP_207587115.1_2894 477 MTFTEVERCEQGeeARQIDSELQCV 501\n",
      "                                                 **********995554455777775 PP\n",
      "\n",
      "\n",
      "\n",
      "Internal pipeline statistics summary:\n",
      "-------------------------------------\n",
      "Query model(s):                              1  (484 nodes)\n",
      "Target sequences:                            1  (617 residues searched)\n",
      "Passed MSV filter:                         1  (1); expected 0.0 (0.02)\n",
      "Passed bias filter:                        1  (1); expected 0.0 (0.02)\n",
      "Passed Vit filter:                         1  (1); expected 0.0 (0.001)\n",
      "Passed Fwd filter:                         1  (1); expected 0.0 (1e-05)\n",
      "Initial search space (Z):                  1  [actual number of targets]\n",
      "Domain search space  (domZ):               1  [number of targets reported over threshold]\n",
      "# CPU time: 0.01u 0.02s 00:00:00.03 Elapsed: 00:00:00.02\n",
      "# Mc/sec: 14.93\n",
      "//\n",
      "[ok]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cat ../data/new_subset/halovivax_seqs/hmmsearch_results/fsx_ectodomain_vs_halovivax_fsxA.hmmsearchout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d8f12ca6-1da5-40d3-b319-37a6dffbaf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract ectodomain sequence\n",
    "halovivax_fsxA_ectodomain_record = halovivax_fsxA_record[0][23:501] # taking into account how to slice in Python, so 23 instead of 24 to start :)\n",
    "halovivax_fsxA_ectodomain_record.id = halovivax_fsxA_record[0].id + '/24-501'\n",
    "halovivax_fsxA_ectodomain_record.name = halovivax_fsxA_record[0].id + '/24-501'\n",
    "\n",
    "# save into FASTA\n",
    "if not os.path.exists('../data/new_subset/halovivax_seqs/halovivax_fsxA_ectodomain.faa'):\n",
    "    with open('../data/new_subset/halovivax_seqs/halovivax_fsxA_ectodomain.faa', 'w') as handle_fasta:\n",
    "        SeqIO.write(halovivax_fsxA_ectodomain_record, handle_fasta, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5875caf0-8c69-407a-ab3a-6deaf79fcd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">lcl|NZ_CP071597.1_prot_WP_207587115.1_2894/24-501\n",
      "AAVTSVDSIQFDSNSKFFSGEVFVIQYISNFDTDRIDVVLSSNDLEQAADGEVDQDLSID\n",
      "VVQQDTAALYSISPSGEPRLGNLELTTAEKSTFEELDRWAWDTCYDINGDGGKEYAYESV\n",
      "LTWSGTVYRGYCARENGFYGPVGRITKDREVFTTEWRVEASGESAQTATLSNGDTGRGVV\n",
      "SDIGDHVKVRWDGNLDTGEEAPPADKEYALHGNQFEDGWRIIDRGRYADWRQHVRDLDTA\n",
      "YEQWRDGDRSRDYLQNQLDTATEQAAAEYTGSPLTSAETVSSTYTDGQLRLEMDTDLAYP\n",
      "SFTVYVDGAEYVSVSKPVGRPEITSTNGDEFGELDTGYVTGTVRNVGDGEGSFAGRLTSC\n",
      "SDGFSFDSTQRTQRVDPGASVTYEFPVSFTSTGDQDEVGGSCTIEVTDTGSGERDFATAA\n",
      "VTGVQENECSPGERFSKVASGGQHVIYQCSEDGMTFTEVERCEQGEEARQIDSELQCV\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cat ../data/new_subset/halovivax_seqs/halovivax_fsxA_ectodomain.faa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce11e33-43f2-442a-8043-51ef75857a07",
   "metadata": {},
   "source": [
    "# Join to previous FASTA, align and infer ectodomain phylogeny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bc5fe16f-bf3d-4a20-a0ff-639093bcd3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get records for FsxA ectodomains\n",
    "fsxA_ectodomains_records = [record for record in SeqIO.parse('../data/new_subset/NewSelEcoTree.fa', 'fasta')]\n",
    "\n",
    "# add this record\n",
    "fsxA_ectodomains_records.append(halovivax_fsxA_ectodomain_record)\n",
    "\n",
    "# save into FASTA\n",
    "if not os.path.exists('../data/new_subset/including_halovivax/NewSelEcoTree_with_Halovivax.fa'):\n",
    "    with open('../data/new_subset/including_halovivax/NewSelEcoTree_with_Halovivax.fa', 'w') as handle_fasta:\n",
    "        SeqIO.write(fsxA_ectodomains_records, handle_fasta, 'fasta')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ad657e-e999-4162-ae1e-bd4e88b84b9c",
   "metadata": {},
   "source": [
    "**Note**: added by hand the sequence for Haloterrigena's ectodomain also!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "03f1c8e8-ed96-4adf-b1c1-103d9b64d892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run MAFFT under linsi\n",
    "if not os.path.exists('../data/new_subset/including_halovivax/NewSelEcoTree_with_Halovivax_linsi.fa'):\n",
    "    out_file = open('../data/new_subset/including_halovivax/NewSelEcoTree_with_Halovivax_linsi.fa', 'w') \n",
    "    fasta_file = '../data/new_subset/including_halovivax/NewSelEcoTree_with_Halovivax.fa'\n",
    "    mafft_command = 'mafft --maxiterate 1000 --localpair {0}'.format(fasta_file).split(' ') # line for L-INS-I\n",
    "    subprocess.run(mafft_command, stdout = out_file)\n",
    "    \n",
    "if not os.path.exists('../data/new_subset/including_halovivax/NewSelEcoTree_iq2.treefile'):\n",
    "        # run IQTree\n",
    "        iqtree_cmd = 'iqtree2 -s ../data/new_subset/including_halovivax/NewSelEcoTree_with_Halovivax_linsi.fa -nt AUTO -m MFP -safe -alrt 1000 -bb 1000 -pre ../data/new_subset/including_halovivax/NewSelEcoTree_iq2'.split(' ')\n",
    "        subprocess.run(iqtree_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682d7682-c893-4443-916d-b8b312aaa06f",
   "metadata": {},
   "source": [
    "# Retrieve metadata of Halovivax from NCBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "00605a63-b29b-417e-85eb-1c017aee0b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from Bio import Entrez\n",
    "import collections\n",
    "\n",
    "# trying for one biosample\n",
    "Entrez.email = 'mauricio.langleib@gmail.com'\n",
    "\n",
    "# create empty list to allocate to allocate rows\n",
    "geo_data_rows = []\n",
    "\n",
    "# loop over BioSample IDs to get geographical data\n",
    "biosample_id = 'SAMN18203374'\n",
    "try:\n",
    "    # retrieve data from BioSample\n",
    "    # first get UID for given BioSample ID\n",
    "    handle = Entrez.esearch(db = 'biosample', term = biosample_id)\n",
    "    biosample_search_dict = Entrez.read(handle)\n",
    "    biosample_uid = biosample_search_dict['IdList']\n",
    "    # now search data for that UID\n",
    "    handle = Entrez.efetch(db = 'biosample', id = biosample_uid, type = 'text')\n",
    "    #print(handle.read())\n",
    "    #biosample_data_dict = Entrez.read(handle)\n",
    "    import xmltodict\n",
    "    biosample_dict = xmltodict.parse(handle)\n",
    "    # getting relevant geographical data\n",
    "    # setting defaults to NA\n",
    "    geo_loc_name = 'NA'\n",
    "    lat = 'NA'\n",
    "    lon = 'NA'\n",
    "    isolation_source = 'NA'\n",
    "    # parsing data\n",
    "    # first case: only one organism annotated\n",
    "    if type(biosample_dict['BioSampleSet']['BioSample']) == collections.OrderedDict:\n",
    "        for attribute in biosample_dict['BioSampleSet']['BioSample']['Attributes']['Attribute']:\n",
    "            if attribute['@attribute_name'] == 'geo_loc_name':\n",
    "                geo_loc_name = attribute['#text']\n",
    "            if attribute['@attribute_name'] == 'lat_lon':\n",
    "                lat = attribute['#text'].split(' ')[0] + ' ' + attribute['#text'].split(' ')[1]\n",
    "                lon = attribute['#text'].split(' ')[2] + ' ' + attribute['#text'].split(' ')[3]\n",
    "            if attribute['@attribute_name'] == 'isolation_source':\n",
    "                isolation_source = attribute['#text']\n",
    "        if 'Description' in biosample_dict['BioSampleSet']['BioSample'].keys():\n",
    "            if 'Title' in biosample_dict['BioSampleSet']['BioSample']['Description'].keys():\n",
    "                title = biosample_dict['BioSampleSet']['BioSample']['Description']['Title']\n",
    "            else:\n",
    "                title = 'NA'\n",
    "            if 'Organism' in biosample_dict['BioSampleSet']['BioSample']['Description'].keys():\n",
    "                if '@taxonomy_id' in biosample_dict['BioSampleSet']['BioSample']['Description']['Organism']:\n",
    "                    taxa_id = biosample_dict['BioSampleSet']['BioSample']['Description']['Organism']['@taxonomy_id']\n",
    "                else:\n",
    "                    taxa_id = 'NA'\n",
    "                if 'OrganismName' in biosample_dict['BioSampleSet']['BioSample']['Description']['Organism']:\n",
    "                    organism = biosample_dict['BioSampleSet']['BioSample']['Description']['Organism']['OrganismName']\n",
    "                else:\n",
    "                    organism = 'NA'\n",
    "        else:\n",
    "            title = 'NA'\n",
    "            taxa_id = 'NA'\n",
    "            organism = 'NA'\n",
    "        # append pandas DataFrame with data to <geo_data_rows>\n",
    "        geo_data_rows.append(pd.DataFrame.from_dict({'BioSample ID': [biosample_id], \n",
    "                                                     'Geographical location': [geo_loc_name], \n",
    "                                                     'Latitude': [str(lat)], \n",
    "                                                     'Longitude': [str(lon)],\n",
    "                                                     'Isolation source': [isolation_source],\n",
    "                                                     'Title': [title],\n",
    "                                                     'Taxa ID': [taxa_id],\n",
    "                                                     'Organism': [organism]}))\n",
    "    elif type(biosample_dict['BioSampleSet']['BioSample']) == list:\n",
    "        for item in biosample_dict['BioSampleSet']['BioSample']:\n",
    "            for attribute in item['Attributes']['Attribute']:\n",
    "                if attribute['@attribute_name'] == 'geo_loc_name':\n",
    "                    geo_loc_name = attribute['#text']\n",
    "                if attribute['@attribute_name'] == 'lat_lon':\n",
    "                    lat = attribute['#text'].split(' ')[0] + ' ' + attribute['#text'].split(' ')[1]\n",
    "                    lon = attribute['#text'].split(' ')[2] + ' ' + attribute['#text'].split(' ')[3]\n",
    "                if attribute['@attribute_name'] == 'isolation_source':\n",
    "                    isolation_source = attribute['#text']\n",
    "            if 'Description' in item.keys():\n",
    "                if 'Title' in item['Description'].keys():\n",
    "                    title = item['Description']['Title']\n",
    "                else:\n",
    "                    title = 'NA'\n",
    "                if 'Organism' in item['Description'].keys():\n",
    "                    if '@taxonomy_id' in item['Description']['Organism'].keys():\n",
    "                        taxa_id = item['Description']['Organism']['@taxonomy_id']\n",
    "                    else:\n",
    "                        taxa_id = 'NA'\n",
    "                    if 'OrganismName' in item['Description']['Organism'].keys():\n",
    "                        organism = item['Description']['Organism']['OrganismName']\n",
    "                    else:\n",
    "                        organism = 'NA'\n",
    "            else:\n",
    "                title = 'NA'\n",
    "                taxa_id = 'NA'\n",
    "                organism = 'NA'\n",
    "            # append pandas DataFrame with data to <geo_data_rows>\n",
    "            geo_data_rows.append(pd.DataFrame.from_dict({'BioSample ID': [biosample_id], \n",
    "                                                         'Geographical location': [geo_loc_name], \n",
    "                                                         'Latitude': [str(lat)], \n",
    "                                                         'Longitude': [str(lon)],\n",
    "                                                         'Isolation source': [isolation_source],\n",
    "                                                         'Title': [title],\n",
    "                                                         'Taxa ID': [taxa_id],\n",
    "                                                         'Organism': [organism]}))               \n",
    "except:\n",
    "    geo_data_rows.append(pd.DataFrame.from_dict({'BioSample ID': [biosample_id], \n",
    "                                                 'Geographical location': ['ERROR'], \n",
    "                                                 'Latitude': [str('ERROR')], \n",
    "                                                 'Longitude': [str('ERROR')],\n",
    "                                                 'Isolation source': ['ERROR'],\n",
    "                                                 'Title': ['ERROR'],\n",
    "                                                 'Taxa ID': ['ERROR'],\n",
    "                                                 'Organism': ['ERROR']}))\n",
    "    \n",
    "halovivax_geo_data_table = pd.concat(geo_data_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "200844b3-3f81-4f8f-9d08-dc6d61485c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BioSample ID</th>\n",
       "      <th>Geographical location</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Isolation source</th>\n",
       "      <th>Title</th>\n",
       "      <th>Taxa ID</th>\n",
       "      <th>Organism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAMN18203374</td>\n",
       "      <td>China</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Salt lake</td>\n",
       "      <td>Microbe sample from Halovivax sp. KZCA124</td>\n",
       "      <td>2817025</td>\n",
       "      <td>Halovivax sp. KZCA124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BioSample ID Geographical location Latitude Longitude Isolation source  \\\n",
       "0  SAMN18203374                 China       NA        NA        Salt lake   \n",
       "\n",
       "                                       Title  Taxa ID               Organism  \n",
       "0  Microbe sample from Halovivax sp. KZCA124  2817025  Halovivax sp. KZCA124  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "halovivax_geo_data_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551ba966-d7e0-439a-bd37-d786f956340e",
   "metadata": {},
   "source": [
    "**Extra info**: Halovivax species appear to be mesophiles that are usually grown under near neutral conditions (e.g. https://www.dsmz.de/collection/catalogue/details/culture/DSM-18321 and its growth medium specification https://www.dsmz.de/microorganisms/medium/pdf/DSMZ_Medium1460.pdf).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d39b1a-c33d-45d0-8478-c59a449fe3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
