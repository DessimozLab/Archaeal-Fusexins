{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf49d250",
   "metadata": {},
   "source": [
    "# Overview\n",
    "Notebook performing homolog group inferences for mobile elements in PCG, MAGs and metagenome assembled contigs of Archaea containing FsxAs.\n",
    "\n",
    "___\n",
    "Workflow of the analysis is as follows (please refere to Suppelementary Figures in order to see a detailed, graphic representation of this pipeline):\n",
    "- Infer ORFs for contigs containing FsxA with *getorf*.\n",
    "- Subsetting annotated features in those contigs.\n",
    "- Stablishing a correlation between predicted ORFs and annotated features (employed later in the analysis).\n",
    "- Infer groups of homologous sequences with *get_homologues*, using predicted ORFs as input sequences.\n",
    "- Subsetting homolog groups containing at least one annotated feature.\n",
    "- Perform remote homologs searches for each homolog group: HMM profiles are created by employing their sequences as queries for a jackhmmer search against UniRef50. HMM profiles are thereafter created, and homolog groups are collapsed by performing pairwise comparisons between them with hhalign.\n",
    "- Filter homolog groups in order to contemplate only sequences present in MEs of a reasonable size\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a224be",
   "metadata": {},
   "source": [
    "# Infer ORFs for contigs containing FsxA with *getorf*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6247ce",
   "metadata": {},
   "source": [
    "## Subsetting mobile elements with hits of FsxA in MAGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88f2db7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loading libraries\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "\n",
    "# load table listing hits of FsxA in MAGs\n",
    "fsxA_hits_in_MAGs_table = pd.read_csv('../data/MAGS/fsxa.MAGS.tab', sep = '\\t', names=['GFF file', 'Contig', 'Annotation source', 'Feature type', 'Start', 'End', 'extra', 'Strand', 'E-value', 'ID'])\n",
    "fsxA_hits_in_MAGs_table\n",
    "contigs_with_fsxA_hits = fsxA_hits_in_MAGs_table['Contig'].to_list()\n",
    "\n",
    "# create dictionary with all MAG contigs\n",
    "genome_fna_files = [fna_file for fna_file in glob.glob('../data/MAGS/ftp.ncbi.nlm.nih.gov/*/*/*/*/*/*/*/*v*_genomic.fna') if not re.match(pattern = '.*rna_from.*|.*cds_from.*', string = fna_file)]\n",
    "\n",
    "# subset contigs of MAGs containing hits of FsxA\n",
    "target_contigs_MAGs = []\n",
    "for fna_file in genome_fna_files:\n",
    "    for record in SeqIO.parse(fna_file, 'fasta'):\n",
    "        if record.id in contigs_with_fsxA_hits:\n",
    "            # get MAG tag\n",
    "            mag_tag = fna_file.split('/')[10].split('_')[1]\n",
    "            target_contigs_MAGs.append((mag_tag, record))\n",
    "\n",
    "# saving contigs of MAGs with hits of FsxA as ME with their code\n",
    "for mag_contig_set in target_contigs_MAGs:\n",
    "    # depacking variables\n",
    "    mag_tag, sequence_record = mag_contig_set\n",
    "    # setting output file name\n",
    "    output_file = '../data/mobile_elements_sequences/ME.{0}.MAG.fna'.format(mag_tag)\n",
    "    if not os.path.exists(output_file):\n",
    "        # saving contig sequence\n",
    "        with open(output_file, 'w') as output_handle:\n",
    "            SeqIO.write(sequence_record, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2f194c",
   "metadata": {},
   "source": [
    "## Formating mobile elements with hits of FsxA in metagenomes\n",
    "Contigs with hits for FsxA in metagenomes are moved to a common folder with those of PCG Archaea and MAGs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a45b91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import library\n",
    "import shutil\n",
    "\n",
    "# list metagenome contig with hits in FsxA (previously subsetted by Dr. Hector Romero)\n",
    "fsxA_hits_in_metagenomes = glob.glob('../data/mobile_elements_sequences_metagenomes/*fasta')\n",
    "\n",
    "# moving these files to common folder with PCG and MAGs Archaea contigs with hits in FsxA\n",
    "for contig_file in fsxA_hits_in_metagenomes:\n",
    "    # getting tag of metagenome\n",
    "    metagenome_tag = contig_file.split('/')[3].replace('.fasta', '')\n",
    "    # create output file name\n",
    "    output_file = '../data/mobile_elements_sequences/ME.{0}.metagenome.fna'.format(metagenome_tag)\n",
    "    # moving\n",
    "    if not os.path.exists(output_file):\n",
    "        shutil.copy(src = contig_file, dst = output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771bb1ed",
   "metadata": {},
   "source": [
    "## Infering ORFs with *getorf*.\n",
    "Script from previous analyses is employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b1e3182",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run getting_orfs.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3033c993",
   "metadata": {},
   "source": [
    "# Subsetting annotated features in those contigs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affd379e",
   "metadata": {},
   "source": [
    "## Running for MAGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03e80cfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence extraction went OK for MAG: 003641755.1\n",
      "Sequence extraction went OK for MAG: 003644925.1\n",
      "Sequence extraction went OK for MAG: 003661485.1\n",
      "Sequence extraction went OK for MAG: 003662005.1\n",
      "Sequence extraction went OK for MAG: 003662775.1\n",
      "Sequence extraction went OK for MAG: 013152655.1\n",
      "Sequence extraction went OK for MAG: 012026795.1\n",
      "Sequence extraction went OK for MAG: 012962785.1\n",
      "Sequence extraction went OK for MAG: 000830315.1\n",
      "Sequence extraction went OK for MAG: 011044075.1\n",
      "Sequence extraction went OK for MAG: 011380245.1\n",
      "Sequence extraction went OK for MAG: 011042275.1\n",
      "Sequence extraction went OK for MAG: 011039335.1\n",
      "Sequence extraction went OK for MAG: 011358415.1\n"
     ]
    }
   ],
   "source": [
    "# creating dictionary with protein annotated for each MAG\n",
    "MAG_proteins_dict = {}\n",
    "for faa_file in glob.glob('../data/MAGS/*/*/*/*/*/*/*/*/*translated_cds.faa'):\n",
    "    # reading proteins\n",
    "    faa_seqs = SeqIO.parse(faa_file, 'fasta')\n",
    "    # adding to dictionary every protein\n",
    "    for record in faa_seqs:\n",
    "        # getting protein name\n",
    "        proteinid = [string.replace('[', '').replace(']', '').replace('protein_id=', '') for string in record.description.split(' ') if re.findall(pattern = 'protein_id', string = string)]\n",
    "        try:\n",
    "            proteinid = proteinid[0]\n",
    "            MAG_proteins_dict.update({proteinid: record})\n",
    "        except:\n",
    "            #print(record)\n",
    "            locus_tag = [string.replace('[', '').replace(']', '').replace('locus_tag=', '') for string in record.description.split(' ') if re.findall(pattern = 'locus_tag', string = string)]\n",
    "            locus_tag = locus_tag[0]\n",
    "            MAG_proteins_dict.update({locus_tag: record})\n",
    "        \n",
    "\n",
    "# list all MAG contigs\n",
    "mag_gff_files = glob.glob('../data/MAGS/ftp.ncbi.nlm.nih.gov/*/*/*/*/*/*/*/*v*gff')\n",
    "\n",
    "# for each MAG\n",
    "for mag_gff_file in mag_gff_files:\n",
    "    # get MAG tag\n",
    "    mag_tag = mag_gff_file.split('/')[10].split('_')[1]\n",
    "    \n",
    "    # charge annotation file\n",
    "    mag_gff = pd.read_csv(mag_gff_file, \n",
    "                          sep = '\\t', \n",
    "                          comment = '#',\n",
    "                          names=['Contig', 'Annotation source', 'Feature type', 'Start', 'End', 'extra', 'Strand', 'E-value', 'ID'])\n",
    "    mag_gff\n",
    "    # get mag target contig\n",
    "    mag_ME_fasta_file = '../data/mobile_elements_sequences/ME.{0}.MAG.fna'.format(mag_tag)\n",
    "    mag_target_contig = [record.id for record in SeqIO.parse(mag_ME_fasta_file, 'fasta')]\n",
    "    # subset for target contig\n",
    "    mag_target_contig\n",
    "    # get features of the contig\n",
    "    mag_ME_annotated_proteins_table = mag_gff.query(\"`Contig` in @mag_target_contig & `Feature type` == 'CDS'\")\n",
    "    mag_ME_annotated_proteins_IDs = [feature.split(';')[0].replace('ID=cds-', '') for feature in mag_ME_annotated_proteins_table['ID'].to_list()]\n",
    "    \n",
    "    # subsetting proteins\n",
    "    mag_ME_protein_seqs = [MAG_proteins_dict[protein_id] for protein_id in mag_ME_annotated_proteins_IDs]\n",
    "    \n",
    "    # modifying ID and description in order to remove white spaces (disturbs future analyses)\n",
    "    for record in mag_ME_protein_seqs:\n",
    "        record.id = record.id.replace(' ', '_')\n",
    "        record.description = record.description.replace(' ', '_')\n",
    "    \n",
    "    # checking that number of extracted sequences is OK\n",
    "    if mag_ME_annotated_proteins_table.shape[0] != len(mag_ME_protein_seqs):\n",
    "        print('Problem extracting sequences of MAG:', mag_tag)\n",
    "    elif mag_ME_annotated_proteins_table.shape[0] == len(mag_ME_protein_seqs):\n",
    "        print('Sequence extraction went OK for MAG:', mag_tag)\n",
    "    # save to file\n",
    "    output_faa_file = '../results/ME_PATRIC_annotated_features/ME.{0}.PATRIC_annotated_features.faa'.format(mag_tag)\n",
    "    if not os.path.exists(output_faa_file):\n",
    "        with open(output_faa_file, 'w') as output_handle:\n",
    "            SeqIO.write(mag_ME_protein_seqs, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ce465b",
   "metadata": {},
   "source": [
    "## Running for metagenomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92f81f41-e00b-4de7-92a6-0c84da68bbe3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence extraction went OK for MAG: ga0075122_10000827\n",
      "Sequence extraction went OK for MAG: ga0207733_100382\n",
      "Sequence extraction went OK for MAG: ga0207718_100100\n",
      "Sequence extraction went OK for MAG: ga0078972_1006503\n",
      "Sequence extraction went OK for MAG: ga0075120_10000694\n",
      "Sequence extraction went OK for MAG: ga0065719_100268\n",
      "Sequence extraction went OK for MAG: ga0172377_10000119\n",
      "Sequence extraction went OK for MAG: ga0172379_10000243\n",
      "Sequence extraction went OK for MAG: ga0172379_10001592\n",
      "Sequence extraction went OK for MAG: ga0207715_100102\n",
      "Sequence extraction went OK for MAG: ga0075122_10000557\n",
      "Sequence extraction went OK for MAG: ga0222667_1000160\n",
      "Sequence extraction went OK for MAG: ga0222658_1000332\n",
      "Sequence extraction went OK for MAG: ga0164313_10000250\n",
      "Sequence extraction went OK for MAG: ga0075122_10000851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauri/anaconda3/envs/r-environment/lib/python3.9/site-packages/Bio/Seq.py:2334: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence extraction went OK for MAG: ga0208375_1000150\n",
      "Sequence extraction went OK for MAG: ga0116200_10000074\n",
      "Sequence extraction went OK for MAG: jgi12330j12834_1000008\n",
      "Sequence extraction went OK for MAG: ga0207719_100190\n"
     ]
    }
   ],
   "source": [
    "# listing metagenome GFF files\n",
    "metagenome_gff_files = glob.glob('../data/metagenome_annotations/*csv')\n",
    "\n",
    "# for each gff file perform pipeline\n",
    "for metagenome_gff_file in metagenome_gff_files:\n",
    "    # loading metagenome contig GFF\n",
    "    metagenome_gff_table = pd.read_csv(metagenome_gff_file, sep = '\\t')\n",
    "    # getting metagenome tag\n",
    "    metagenome_tag = metagenome_gff_file.split('/')[3].replace('.csv', '').lower().split('.')[0]\n",
    "    # create dictionary to allocate target sequences\n",
    "    metagenome_cds_seqs = []\n",
    "    metagenome_aa_seqs = []\n",
    "    # loading fna file\n",
    "    metagenome_contig_dna_file = '../data/mobile_elements_sequences/ME.{0}.metagenome.fna'.format(metagenome_tag)\n",
    "    metagenome_contig_dna = [record for record in SeqIO.parse(metagenome_contig_dna_file, 'fasta')]\n",
    "    metagenome_contig_dna = metagenome_contig_dna[0]\n",
    "    # creating dictionaries to allocate sequences\n",
    "    metagenoma_CDS_seqs = []\n",
    "    metagenoma_AA_seqs = []\n",
    "    # extracting CDS sequence for each feature in target contig\n",
    "    for index, row in metagenome_gff_table.iterrows():\n",
    "        # set variables\n",
    "        gene_id = row['Gene ID']\n",
    "        gene_name = row['Gene Product Name']\n",
    "        start = row['Start Coord']\n",
    "        end = row['End Coord']\n",
    "        strand = row['Strand']\n",
    "        # getting sequence and storing it in corresponding dictionary\n",
    "        cds_seq = metagenome_contig_dna[start-1:end]\n",
    "        # taking into account strandedness\n",
    "        if strand == '-':\n",
    "            cds_seq = cds_seq.reverse_complement()\n",
    "        cds_seq.id = gene_id\n",
    "        cds_seq.description = gene_name \n",
    "        metagenoma_CDS_seqs.append(cds_seq)\n",
    "        # translating sequence and storing it in corresponding dictionary\n",
    "        aa_seq = SeqIO.SeqRecord(seq = cds_seq.seq.translate(table = 11), \n",
    "                           id = gene_id.replace(' ', '_'),\n",
    "                           description = gene_name.replace(' ', '_'))\n",
    "        metagenoma_AA_seqs.append(aa_seq)\n",
    "    # checking that numbers of extracted seqs are OK\n",
    "    if metagenome_gff_table.shape[0] != len(metagenoma_AA_seqs):\n",
    "        print('Problem extracting sequences of MAG:', metagenome_tag)\n",
    "    elif metagenome_gff_table.shape[0] == len(metagenoma_AA_seqs):\n",
    "        print('Sequence extraction went OK for MAG:', metagenome_tag)\n",
    "    # saving protein FASTA file\n",
    "    output_faa_file = '../results/ME_PATRIC_annotated_features/ME.{0}.PATRIC_annotated_features.faa'.format(metagenome_tag)\n",
    "    if not os.path.exists(output_faa_file):\n",
    "        with open(output_faa_file, 'w') as output_handle:\n",
    "            SeqIO.write(metagenoma_AA_seqs, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae14bfc5-b3f4-489a-b8d7-b58f7ba1b3a5",
   "metadata": {},
   "source": [
    "## Running for PCG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cc9845-cf34-493f-8d50-4547ae863735",
   "metadata": {},
   "source": [
    "### First locating ME in genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59a38f2d-8ddc-4196-b0c3-ec8b2d189fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# getting MEs coordinates in genomes in order to parse coding sequences in them\n",
    "# creating list with 2-uple storing ME file and genome file\n",
    "me_data = [(ME.replace('ME.', '').replace('.fna', ''),\n",
    "            '../data/mobile_elements_sequences/{0}'.format(ME), \n",
    "            '../data/genome_annotations/{0}/{0}.fna'.format(ME.replace('ME.', '').replace('.fna', ''))) for ME in os.listdir('../data/mobile_elements_sequences/')]\n",
    "\n",
    "# creating some directories to store results and databases\n",
    "for directory in ['../data/genome_blastdbs', '../results/MEs_against_genomes']:\n",
    "  if not os.path.exists(directory):\n",
    "    os.mkdir(directory)\n",
    "\n",
    "# creating BLAST nucleotidic database for each genome\n",
    "for data in me_data:\n",
    "  # unpacking variables\n",
    "  genome_tag, mobile_element, genome = data\n",
    "  # create BLAST database\n",
    "  make_blastdb_command = 'makeblastdb -in {0} -dbtype nucl -out ../data/genome_blastdbs/{1}_db -parse_seqids'.format(genome, genome_tag).split(' ')\n",
    "  subprocess.run(make_blastdb_command)\n",
    "  # BLASTN ME against the respective genome\n",
    "  blastn_command = \"blastn -db ../data/genome_blastdbs/{0}_db -query {1} -out ../results/MEs_against_genomes/ME.{0}_vs_{0}.blout -evalue 1e-5 -num_threads 1 -outfmt 6\".format(genome_tag, mobile_element).split(' ')\n",
    "  subprocess.run(blastn_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b405ab28-1376-4dc3-af8a-ddf62208d965",
   "metadata": {},
   "source": [
    "### Extracting annotated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87e1bcbc-9ef7-4611-8dac-0d060803105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary with protein annotated for each MAG\n",
    "import gzip\n",
    "\n",
    "halovivax_proteins_dict = {}\n",
    "for faa_file in glob.glob('../data/halovivax/GCF_017357405.1_ASM1735740v1_translated_cds.faa.gz'):\n",
    "    # reading proteins\n",
    "    #faa_seqs = SeqIO.parse(faa_file, 'fasta')\n",
    "    #faa_seqs = []\n",
    "    with gzip.open(faa_file, \"rt\") as handle:\n",
    "        faa_seqs = [record for record in SeqIO.parse(handle, \"fasta\")]\n",
    "    # adding to dictionary every protein\n",
    "    for record in faa_seqs:\n",
    "        # getting protein name\n",
    "        proteinid = [string.replace('[', '').replace(']', '').replace('protein_id=', '') for string in record.description.split(' ') if re.findall(pattern = 'protein_id', string = string)]\n",
    "        try:\n",
    "            proteinid = proteinid[0]\n",
    "            halovivax_proteins_dict.update({proteinid: record})\n",
    "        except:\n",
    "            #print(record)\n",
    "            locus_tag = [string.replace('[', '').replace(']', '').replace('locus_tag=', '') for string in record.description.split(' ') if re.findall(pattern = 'locus_tag', string = string)]\n",
    "            locus_tag = locus_tag[0]\n",
    "            halovivax_proteins_dict.update({locus_tag: record})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f13503b-b998-4b5c-b4cd-b4f0176f3364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qseqid</th>\n",
       "      <th>sseqid</th>\n",
       "      <th>pident</th>\n",
       "      <th>length</th>\n",
       "      <th>mismatch</th>\n",
       "      <th>gapopen</th>\n",
       "      <th>qstart</th>\n",
       "      <th>qend</th>\n",
       "      <th>sstart</th>\n",
       "      <th>send</th>\n",
       "      <th>evalue</th>\n",
       "      <th>bitscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NZ_CP071597.1</td>\n",
       "      <td>NZ_CP071597.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>94500</td>\n",
       "      <td>3085001</td>\n",
       "      <td>3179500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          qseqid         sseqid  pident  length  mismatch  gapopen  qstart  \\\n",
       "0  NZ_CP071597.1  NZ_CP071597.1   100.0   94500         0        0       1   \n",
       "\n",
       "    qend   sstart     send  evalue  bitscore  \n",
       "0  94500  3085001  3179500     0.0  174500.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting contig hit and start and end of mobile element\n",
    "blastn_outfmt_columns = ['qseqid', 'sseqid', 'pident', 'length', 'mismatch', 'gapopen', 'qstart', 'qend', 'sstart', 'send', 'evalue', 'bitscore']\n",
    "halovivax_blast_hit = pd.read_csv('../results/MEs_against_genomes/ME.017357405.1_vs_017357405.1.blout', sep = '\\t', names = blastn_outfmt_columns)\n",
    "\n",
    "halovivax_blast_hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "752d9cf4-5cc6-404b-b442-674b22725bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contig</th>\n",
       "      <th>Annotation source</th>\n",
       "      <th>Feature type</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>extra</th>\n",
       "      <th>Strand</th>\n",
       "      <th>E-value</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5825</th>\n",
       "      <td>NZ_CP071597.1</td>\n",
       "      <td>Protein Homology</td>\n",
       "      <td>CDS</td>\n",
       "      <td>3085325</td>\n",
       "      <td>3085912</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-WP_207587062.1;Parent=gene-J1N62_RS1446...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5827</th>\n",
       "      <td>NZ_CP071597.1</td>\n",
       "      <td>GeneMarkS-2+</td>\n",
       "      <td>CDS</td>\n",
       "      <td>3085939</td>\n",
       "      <td>3086346</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-WP_207587064.1;Parent=gene-J1N62_RS1447...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5829</th>\n",
       "      <td>NZ_CP071597.1</td>\n",
       "      <td>GeneMarkS-2+</td>\n",
       "      <td>CDS</td>\n",
       "      <td>3086605</td>\n",
       "      <td>3086787</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-WP_207587066.1;Parent=gene-J1N62_RS1447...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5831</th>\n",
       "      <td>NZ_CP071597.1</td>\n",
       "      <td>GeneMarkS-2+</td>\n",
       "      <td>CDS</td>\n",
       "      <td>3086855</td>\n",
       "      <td>3088243</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-WP_207587068.1;Parent=gene-J1N62_RS1448...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>NZ_CP071597.1</td>\n",
       "      <td>GeneMarkS-2+</td>\n",
       "      <td>CDS</td>\n",
       "      <td>3088236</td>\n",
       "      <td>3088883</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-WP_207587070.1;Parent=gene-J1N62_RS1448...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Contig Annotation source Feature type    Start      End extra  \\\n",
       "5825  NZ_CP071597.1  Protein Homology          CDS  3085325  3085912     .   \n",
       "5827  NZ_CP071597.1      GeneMarkS-2+          CDS  3085939  3086346     .   \n",
       "5829  NZ_CP071597.1      GeneMarkS-2+          CDS  3086605  3086787     .   \n",
       "5831  NZ_CP071597.1      GeneMarkS-2+          CDS  3086855  3088243     .   \n",
       "5833  NZ_CP071597.1      GeneMarkS-2+          CDS  3088236  3088883     .   \n",
       "\n",
       "     Strand E-value                                                 ID  \n",
       "5825      -       0  ID=cds-WP_207587062.1;Parent=gene-J1N62_RS1446...  \n",
       "5827      -       0  ID=cds-WP_207587064.1;Parent=gene-J1N62_RS1447...  \n",
       "5829      +       0  ID=cds-WP_207587066.1;Parent=gene-J1N62_RS1447...  \n",
       "5831      -       0  ID=cds-WP_207587068.1;Parent=gene-J1N62_RS1448...  \n",
       "5833      -       0  ID=cds-WP_207587070.1;Parent=gene-J1N62_RS1448...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mag_gff_file = '../data/genome_annotations/017357405.1/017357405.1.gff'\n",
    "mag_tag = mag_gff_file.split('/')[3]    \n",
    "# charge annotation file\n",
    "mag_gff = pd.read_csv(mag_gff_file, \n",
    "                      sep = '\\t', \n",
    "                      comment = '#',\n",
    "                      names=['Contig', 'Annotation source', 'Feature type', 'Start', 'End', 'extra', 'Strand', 'E-value', 'ID'])\n",
    "mag_gff\n",
    "# get mag target contig\n",
    "mag_ME_fasta_file = '../data/mobile_elements_sequences/ME.{0}.fna'.format(mag_tag)\n",
    "mag_target_contig = halovivax_blast_hit['sseqid'].to_list()\n",
    "mag_target_start = halovivax_blast_hit['sstart'].to_list()[0]\n",
    "mag_target_end = halovivax_blast_hit['send'].to_list()[0]\n",
    "# subset for target contig\n",
    "mag_target_contig\n",
    "# get features of the contig\n",
    "mag_ME_annotated_proteins_table = mag_gff.query(\"`Contig` in @mag_target_contig & `Feature type` == 'CDS' & Start >= @mag_target_start & End <= @mag_target_end\")\n",
    "\n",
    "mag_ME_annotated_proteins_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "896c5ffb-9d49-48dc-9d5f-011f41d4fce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence extraction went OK for MAG: 017357405.1\n"
     ]
    }
   ],
   "source": [
    "# list all MAG contigs\n",
    "halovivax_gff_files = glob.glob('../data/genome_annotations/017357405.1/017357405.1.gff')\n",
    "\n",
    "# for each MAG\n",
    "for mag_gff_file in halovivax_gff_files:\n",
    "    # get MAG tag\n",
    "    mag_tag = mag_gff_file.split('/')[3]\n",
    "    \n",
    "    # charge annotation file\n",
    "    mag_gff = pd.read_csv(mag_gff_file, \n",
    "                          sep = '\\t', \n",
    "                          comment = '#',\n",
    "                          names=['Contig', 'Annotation source', 'Feature type', 'Start', 'End', 'extra', 'Strand', 'E-value', 'ID'])\n",
    "    mag_gff\n",
    "    # get mag target contig\n",
    "    mag_ME_fasta_file = '../data/mobile_elements_sequences/ME.{0}.fna'.format(mag_tag)\n",
    "    mag_target_contig = halovivax_blast_hit['sseqid'].to_list()\n",
    "    mag_target_start = halovivax_blast_hit['sstart'].to_list()[0]\n",
    "    mag_target_end = halovivax_blast_hit['send'].to_list()[0]\n",
    "    # subset for target contig\n",
    "    mag_target_contig\n",
    "    # get features of the contig\n",
    "    mag_ME_annotated_proteins_table = mag_gff.query(\"`Contig` in @mag_target_contig & `Feature type` == 'CDS' & Start >= @mag_target_start & End <= @mag_target_end\")\n",
    "    mag_ME_annotated_proteins_IDs = [feature.split(';')[0].replace('ID=cds-', '') for feature in mag_ME_annotated_proteins_table['ID'].to_list()]\n",
    "    \n",
    "    # subsetting proteins\n",
    "    mag_ME_protein_seqs = [halovivax_proteins_dict[protein_id] for protein_id in mag_ME_annotated_proteins_IDs]\n",
    "    \n",
    "    # modifying ID and description in order to remove white spaces (disturbs future analyses)\n",
    "    for record in mag_ME_protein_seqs:\n",
    "        record.id = record.id.replace(' ', '_')\n",
    "        record.description = record.description.replace(' ', '_')\n",
    "    \n",
    "    # checking that number of extracted sequences is OK\n",
    "    if mag_ME_annotated_proteins_table.shape[0] != len(mag_ME_protein_seqs):\n",
    "        print('Problem extracting sequences of MAG:', mag_tag)\n",
    "    elif mag_ME_annotated_proteins_table.shape[0] == len(mag_ME_protein_seqs):\n",
    "        print('Sequence extraction went OK for MAG:', mag_tag)\n",
    "    # save to file\n",
    "    output_faa_file = '../results/ME_PATRIC_annotated_features/ME.{0}.PATRIC_annotated_features.faa'.format(mag_tag)\n",
    "    if not os.path.exists(output_faa_file):\n",
    "        with open(output_faa_file, 'w') as output_handle:\n",
    "            SeqIO.write(mag_ME_protein_seqs, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "142fc0b5-9d24-4dd0-883a-a739857c2afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contig</th>\n",
       "      <th>Annotation source</th>\n",
       "      <th>Feature type</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>extra</th>\n",
       "      <th>Strand</th>\n",
       "      <th>E-value</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5825</th>\n",
       "      <td>NZ_CP071597.1</td>\n",
       "      <td>Protein Homology</td>\n",
       "      <td>CDS</td>\n",
       "      <td>3085325</td>\n",
       "      <td>3085912</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-WP_207587062.1;Parent=gene-J1N62_RS1446...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5827</th>\n",
       "      <td>NZ_CP071597.1</td>\n",
       "      <td>GeneMarkS-2+</td>\n",
       "      <td>CDS</td>\n",
       "      <td>3085939</td>\n",
       "      <td>3086346</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-WP_207587064.1;Parent=gene-J1N62_RS1447...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5829</th>\n",
       "      <td>NZ_CP071597.1</td>\n",
       "      <td>GeneMarkS-2+</td>\n",
       "      <td>CDS</td>\n",
       "      <td>3086605</td>\n",
       "      <td>3086787</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-WP_207587066.1;Parent=gene-J1N62_RS1447...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5831</th>\n",
       "      <td>NZ_CP071597.1</td>\n",
       "      <td>GeneMarkS-2+</td>\n",
       "      <td>CDS</td>\n",
       "      <td>3086855</td>\n",
       "      <td>3088243</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-WP_207587068.1;Parent=gene-J1N62_RS1448...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>NZ_CP071597.1</td>\n",
       "      <td>GeneMarkS-2+</td>\n",
       "      <td>CDS</td>\n",
       "      <td>3088236</td>\n",
       "      <td>3088883</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-WP_207587070.1;Parent=gene-J1N62_RS1448...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>NZ_CP071597.1</td>\n",
       "      <td>Protein Homology</td>\n",
       "      <td>CDS</td>\n",
       "      <td>3175529</td>\n",
       "      <td>3176281</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-WP_207587203.1;Parent=gene-J1N62_RS1500...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6041</th>\n",
       "      <td>NZ_CP071597.1</td>\n",
       "      <td>GeneMarkS-2+</td>\n",
       "      <td>CDS</td>\n",
       "      <td>3176288</td>\n",
       "      <td>3176635</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-WP_207587205.1;Parent=gene-J1N62_RS1500...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>NZ_CP071597.1</td>\n",
       "      <td>GeneMarkS-2+</td>\n",
       "      <td>CDS</td>\n",
       "      <td>3176846</td>\n",
       "      <td>3177706</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-WP_207587207.1;Parent=gene-J1N62_RS1501...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6045</th>\n",
       "      <td>NZ_CP071597.1</td>\n",
       "      <td>GeneMarkS-2+</td>\n",
       "      <td>CDS</td>\n",
       "      <td>3178015</td>\n",
       "      <td>3178596</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-WP_207587209.1;Parent=gene-J1N62_RS1501...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>NZ_CP071597.1</td>\n",
       "      <td>Protein Homology</td>\n",
       "      <td>CDS</td>\n",
       "      <td>3178752</td>\n",
       "      <td>3179168</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-WP_207592150.1;Parent=gene-J1N62_RS1502...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Contig Annotation source Feature type    Start      End extra  \\\n",
       "5825  NZ_CP071597.1  Protein Homology          CDS  3085325  3085912     .   \n",
       "5827  NZ_CP071597.1      GeneMarkS-2+          CDS  3085939  3086346     .   \n",
       "5829  NZ_CP071597.1      GeneMarkS-2+          CDS  3086605  3086787     .   \n",
       "5831  NZ_CP071597.1      GeneMarkS-2+          CDS  3086855  3088243     .   \n",
       "5833  NZ_CP071597.1      GeneMarkS-2+          CDS  3088236  3088883     .   \n",
       "...             ...               ...          ...      ...      ...   ...   \n",
       "6039  NZ_CP071597.1  Protein Homology          CDS  3175529  3176281     .   \n",
       "6041  NZ_CP071597.1      GeneMarkS-2+          CDS  3176288  3176635     .   \n",
       "6043  NZ_CP071597.1      GeneMarkS-2+          CDS  3176846  3177706     .   \n",
       "6045  NZ_CP071597.1      GeneMarkS-2+          CDS  3178015  3178596     .   \n",
       "6047  NZ_CP071597.1  Protein Homology          CDS  3178752  3179168     .   \n",
       "\n",
       "     Strand E-value                                                 ID  \n",
       "5825      -       0  ID=cds-WP_207587062.1;Parent=gene-J1N62_RS1446...  \n",
       "5827      -       0  ID=cds-WP_207587064.1;Parent=gene-J1N62_RS1447...  \n",
       "5829      +       0  ID=cds-WP_207587066.1;Parent=gene-J1N62_RS1447...  \n",
       "5831      -       0  ID=cds-WP_207587068.1;Parent=gene-J1N62_RS1448...  \n",
       "5833      -       0  ID=cds-WP_207587070.1;Parent=gene-J1N62_RS1448...  \n",
       "...     ...     ...                                                ...  \n",
       "6039      +       0  ID=cds-WP_207587203.1;Parent=gene-J1N62_RS1500...  \n",
       "6041      +       0  ID=cds-WP_207587205.1;Parent=gene-J1N62_RS1500...  \n",
       "6043      +       0  ID=cds-WP_207587207.1;Parent=gene-J1N62_RS1501...  \n",
       "6045      +       0  ID=cds-WP_207587209.1;Parent=gene-J1N62_RS1501...  \n",
       "6047      -       0  ID=cds-WP_207592150.1;Parent=gene-J1N62_RS1502...  \n",
       "\n",
       "[112 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mag_ME_annotated_proteins_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3728553-0512-4334-a606-ae9837f19825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the other PCGs\n",
    "pcg_list = [filename.rpartition('/')[2].replace('ME.', '').replace('.fna', '') for filename in glob.glob('/home/mauri/fusogenos/fusexins/FsxA/analysis_mobile_elements/data/mobile_elements_sequences/*.fna')] # create list of PCG IDs by parsing first analyses\n",
    "pcg_gffs = ['../data/genome_annotations/{0}/{0}.PATRIC.gff'.format(genome_id) for genome_id in pcg_list] # create path of GFFs\n",
    "pcg_blast_files = ['../results/MEs_against_genomes/ME.{0}_vs_{0}.blout'.format(genome_id) for genome_id in pcg_list]\n",
    "pcg_blast_dict = {} # create dictionary of BLASTN results\n",
    "\n",
    "for blast_file_pack in zip(pcg_list, pcg_blast_files):\n",
    "    genome_id, blast_file = blast_file_pack # depack variables\n",
    "    blastn_outfmt_columns = ['qseqid', 'sseqid', 'pident', 'length', 'mismatch', 'gapopen', 'qstart', 'qend', 'sstart', 'send', 'evalue', 'bitscore'] # set column names\n",
    "    blast_hit_table = pd.read_csv(blast_file, sep = '\\t', names = blastn_outfmt_columns).query(\"`mismatch` == 0 & `evalue` == 0\") # get table\n",
    "    pcg_blast_dict.update({genome_id: blast_hit_table}) # update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdf2227b-d90c-4228-b411-aafaa3ad9238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary with PCG proteins\n",
    "pcg_protein_dict = {}\n",
    "\n",
    "for protein_fasta in ['../data/genome_annotations/{0}/{0}.PATRIC.faa'.format(genome_id) for genome_id in pcg_list]: # iterate over files of proteins\n",
    "    genome_id = protein_fasta.split('/')[3] # get genome_id\n",
    "    genome_records = [record for record in SeqIO.parse(protein_fasta, 'fasta')] # load records\n",
    "    pcg_protein_dict.update({genome_id: {}}) # intialize key\n",
    "    for record in genome_records:\n",
    "        pcg_protein_dict[genome_id].update({'|'.join(record.id.split('|')[0:2]): record}) # append record list under genome_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac7a0886-2086-4e70-8476-f05127c934f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each PCG\n",
    "for mag_gff_file in pcg_gffs:\n",
    "    # get MAG tag\n",
    "    mag_tag = mag_gff_file.split('/')[3]\n",
    "    # save to file\n",
    "    output_faa_file = '../results/ME_PATRIC_annotated_features/ME.{0}.PATRIC_annotated_features.faa'.format(mag_tag)\n",
    "    if not os.path.exists(output_faa_file):\n",
    "        # charge annotation file\n",
    "        mag_gff = pd.read_csv(mag_gff_file, \n",
    "                              sep = '\\t', \n",
    "                              comment = '#',\n",
    "                              names=['Contig', 'Annotation source', 'Feature type', 'Start', 'End', 'extra', 'Strand', 'E-value', 'ID'])\n",
    "        mag_gff['Contig'] = [contig.replace('accn|', '') for contig in mag_gff['Contig'].to_list()] # modify contig name\n",
    "        mag_gff\n",
    "        # get mag target contig\n",
    "        mag_ME_fasta_file = '../data/mobile_elements_sequences/ME.{0}.fna'.format(mag_tag)\n",
    "        mag_target_contig = pcg_blast_dict[mag_tag]['sseqid'].to_list()[0]\n",
    "        mag_target_start = pcg_blast_dict[mag_tag]['sstart'].to_list()[0]\n",
    "        mag_target_end = pcg_blast_dict[mag_tag]['send'].to_list()[0]\n",
    "        # subset for target contig\n",
    "        mag_target_contig\n",
    "        # get features of the contig\n",
    "        mag_ME_annotated_proteins_table = mag_gff.query(\"`Contig` in @mag_target_contig & `Feature type` == 'CDS' & Start >= @mag_target_start & End <= @mag_target_end\")\n",
    "        mag_ME_annotated_proteins_IDs = [feature.split(';')[0].replace('ID=', '') for feature in mag_ME_annotated_proteins_table['ID'].to_list()]\n",
    "        \n",
    "        # subsetting proteins\n",
    "        mag_ME_protein_seqs = [pcg_protein_dict[mag_tag][protein_id] for protein_id in mag_ME_annotated_proteins_IDs if protein_id in pcg_protein_dict[mag_tag].keys()]\n",
    "        \n",
    "        # modifying ID and description in order to remove white spaces (disturbs future analyses)\n",
    "        #for record in mag_ME_protein_seqs:\n",
    "        #    record.id = record.id.replace(' ', '_')\n",
    "        #    record.description = record.description.replace(' ', '_')\n",
    "        \n",
    "        # checking that number of extracted sequences is OK\n",
    "        if mag_ME_annotated_proteins_table.shape[0] != len(mag_ME_protein_seqs):\n",
    "            print('Problem extracting sequences of MAG:', mag_tag)\n",
    "        elif mag_ME_annotated_proteins_table.shape[0] == len(mag_ME_protein_seqs):\n",
    "            print('Sequence extraction went OK for MAG:', mag_tag)\n",
    "        # save to file\n",
    "        output_faa_file = '../results/ME_PATRIC_annotated_features/ME.{0}.PATRIC_annotated_features.faa'.format(mag_tag)\n",
    "        if not os.path.exists(output_faa_file):\n",
    "            with open(output_faa_file, 'w') as output_handle:\n",
    "                SeqIO.write(mag_ME_protein_seqs, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a0107fc-811d-4961-8311-962231ba753c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence extraction went OK for MAG: 017357405.1\n"
     ]
    }
   ],
   "source": [
    "# list all MAG contigs\n",
    "halovivax_gff_files = glob.glob('../data/genome_annotations/017357405.1/017357405.1.gff')\n",
    "\n",
    "# for each MAG\n",
    "for mag_gff_file in halovivax_gff_files:\n",
    "    # get MAG tag\n",
    "    mag_tag = mag_gff_file.split('/')[3]\n",
    "    \n",
    "    # charge annotation file\n",
    "    mag_gff = pd.read_csv(mag_gff_file, \n",
    "                          sep = '\\t', \n",
    "                          comment = '#',\n",
    "                          names=['Contig', 'Annotation source', 'Feature type', 'Start', 'End', 'extra', 'Strand', 'E-value', 'ID'])\n",
    "    mag_gff\n",
    "    # get mag target contig\n",
    "    mag_ME_fasta_file = '../data/mobile_elements_sequences/ME.{0}.fna'.format(mag_tag)\n",
    "    mag_target_contig = halovivax_blast_hit['sseqid'].to_list()\n",
    "    mag_target_start = halovivax_blast_hit['sstart'].to_list()[0]\n",
    "    mag_target_end = halovivax_blast_hit['send'].to_list()[0]\n",
    "    # subset for target contig\n",
    "    mag_target_contig\n",
    "    # get features of the contig\n",
    "    mag_ME_annotated_proteins_table = mag_gff.query(\"`Contig` in @mag_target_contig & `Feature type` == 'CDS' & Start >= @mag_target_start & End <= @mag_target_end\")\n",
    "    mag_ME_annotated_proteins_IDs = [feature.split(';')[0].replace('ID=cds-', '') for feature in mag_ME_annotated_proteins_table['ID'].to_list()]\n",
    "    \n",
    "    # subsetting proteins\n",
    "    mag_ME_protein_seqs = [halovivax_proteins_dict[protein_id] for protein_id in mag_ME_annotated_proteins_IDs]\n",
    "    \n",
    "    # modifying ID and description in order to remove white spaces (disturbs future analyses)\n",
    "    for record in mag_ME_protein_seqs:\n",
    "        record.id = record.id.replace(' ', '_')\n",
    "        record.description = record.description.replace(' ', '_')\n",
    "    \n",
    "    # checking that number of extracted sequences is OK\n",
    "    if mag_ME_annotated_proteins_table.shape[0] != len(mag_ME_protein_seqs):\n",
    "        print('Problem extracting sequences of MAG:', mag_tag)\n",
    "    elif mag_ME_annotated_proteins_table.shape[0] == len(mag_ME_protein_seqs):\n",
    "        print('Sequence extraction went OK for MAG:', mag_tag)\n",
    "    # save to file\n",
    "    output_faa_file = '../results/ME_PATRIC_annotated_features/ME.{0}.PATRIC_annotated_features.faa'.format(mag_tag)\n",
    "    if not os.path.exists(output_faa_file):\n",
    "        with open(output_faa_file, 'w') as output_handle:\n",
    "            SeqIO.write(mag_ME_protein_seqs, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d050a7b3",
   "metadata": {},
   "source": [
    "# Infer groups of homologous sequences \n",
    "Groups of homologous sequences are infered with *get_homologues*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fe5fd1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#nohup /home/mauri/programas/get_homologues-x86_64-20210305/get_homologues.pl -e -d ../results/MEs_predicted_orfs/ -t 0 -m local -n 10 -C 70 -S 35 -M 1 &> nohup.get_homologues_ORFs_identity35_no_inparalogs.out &\n",
    "#mv MEs_predicted_orfs_homologues ../results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3dc67d",
   "metadata": {},
   "source": [
    "# Stablishing a correlation between predicted ORFs and annotated features\n",
    "Also renaming ORFs in order to get nice names to work with. Saving a correlation table afterwards. Also subsetting homolog groups containing at least one annotated feature in respective source database.\n",
    "\n",
    "Running in a separate notebook (parsing_orf_homolog_groups.ipynb) because of conda environment incompatibilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e7fcc1",
   "metadata": {},
   "source": [
    "## Copying genome files of MAGs and metagenomes into common folder with those of PCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d42721e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create auxiliary function\n",
    "def create_dir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "\n",
    "# copying process for MAGs\n",
    "# listing MAGs genome files\n",
    "genome_fna_files = [fna_file for fna_file in glob.glob('../data/MAGS/ftp.ncbi.nlm.nih.gov/*/*/*/*/*/*/*/*v*_genomic.fna') if not re.match(pattern = '.*rna_from.*|.*cds_from.*', string = fna_file)]\n",
    "# iterate over files\n",
    "for fna_file in genome_fna_files:\n",
    "    # get MAG tag\n",
    "    mag_tag = fna_file.split('/')[10].split('_')[1]\n",
    "    # create allocating folder\n",
    "    output_mag_genome_folder = '../data/genome_annotations/{0}'.format(mag_tag)\n",
    "    create_dir(output_mag_genome_folder)\n",
    "    # create output file name\n",
    "    output_mag_genome_file = '{0}/{1}.fna'.format(output_mag_genome_folder, mag_tag)\n",
    "    # copy from source location to destination folder\n",
    "    shutil.copyfile(src = fna_file, dst = output_mag_genome_file)\n",
    "    \n",
    "# copying process for metagenomes\n",
    "# listing metagenome files\n",
    "metagenome_fna_files = glob.glob('../data/mobile_elements_sequences_metagenomes/*fasta')\n",
    "# iterating over files\n",
    "for metagenome_fna_file in metagenome_fna_files:\n",
    "    # get metagenome tag\n",
    "    metagenome_tag = metagenome_fna_file.split('/')[3].replace('.fasta', '').lower().split('.')[0]\n",
    "    # create allocating folder\n",
    "    output_metagenome_genome_folder = '../data/genome_annotations/{0}'.format(metagenome_tag)\n",
    "    create_dir(output_metagenome_genome_folder)\n",
    "    # create output file name\n",
    "    output_metagenome_genome_file = '{0}/{1}.fna'.format(output_metagenome_genome_folder, metagenome_tag)\n",
    "    # copy from source location to destination folder\n",
    "    shutil.copyfile(src = metagenome_fna_file, dst = output_metagenome_genome_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020c1cbe",
   "metadata": {},
   "source": [
    "## Updating *genomes_and_taxonomy.csv* with info of MAGs and metagenomes\n",
    "Species names and their genome ID codes are stored in the table *genomes_and_taxonomy.csv*, which already has information regarding PCG Archaea.\n",
    "API requests are performed to get information for MAGs (from **GTDB database**; https://gtdb.ecogenomic.org/) and metagenomes (from **JGI portal**; https://genome.jgi.doe.gov/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3528d743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import library to perform API calls\n",
    "import requests\n",
    "\n",
    "# trying first API request for GTDB\n",
    "# create list to allocate pandas DataFrame with data\n",
    "mag_species_data = []\n",
    "\n",
    "# getting MAG Genome IDs\n",
    "mag_genome_ids = [mag_gff_file.split('/')[10].rpartition('_')[0] for mag_gff_file in mag_gff_files]\n",
    "# adding mag_genome_id for MAG without annotation\n",
    "mag_genome_ids = mag_genome_ids + ['GCA_001563915.1']\n",
    "# iterating over MAG IDs\n",
    "for mag_genome_id in mag_genome_ids:\n",
    "    # performing API request\n",
    "    response = requests.get('https://gtdb.ecogenomic.org/api/v1/genome/summary/{0}'.format(mag_genome_id))\n",
    "    # getting request JSON data structure\n",
    "    mag_genome_json = response.json()\n",
    "    # getting species name for Genome ID\n",
    "    # contamplating possible scenarios\n",
    "    if mag_genome_json['gtdb_species'] != 's__':\n",
    "        mag_genome_phylum = mag_genome_json['gtdb_phylum'].split('p__')[1].replace(' ', '_')\n",
    "        mag_genome_species = mag_genome_json['gtdb_species'].split('s__')[1].replace(' ', '_')        \n",
    "    elif mag_genome_json['gtdb_species'] == 's__':\n",
    "        mag_genome_phylum = mag_genome_json['ncbi_taxonomy'].split(';')[1].split('p__')[1].replace(' ', '_')\n",
    "        mag_genome_species = mag_genome_json['ncbi_taxonomy'].split(';')[6].split('s__')[1].replace(' ', '_')\n",
    "    # contamplating empty string for species\n",
    "    if mag_genome_species == '':\n",
    "        mag_genome_species = mag_genome_id.rpartition('.')[0]\n",
    "    # adding pandas DataFrame to <mag_species_data>\n",
    "    mag_genome_full_data = '_'.join([mag_genome_phylum, mag_genome_species])\n",
    "    mag_species_data.append(pd.DataFrame.from_dict({'Genome_id': [mag_genome_id], 'Taxonomy': [mag_genome_full_data]}))\n",
    "# concatenating to create table\n",
    "mag_species_data_table = pd.concat(mag_species_data)\n",
    "\n",
    "# the case of metagenomes is a bit different because metadata seems to have long and uninformative/too-informative names, with no taxon clasiffication for contigs\n",
    "# going to perform a replication of genome id in this case\n",
    "metagenome_species_data = []\n",
    "# listing metagenome files\n",
    "metagenome_fna_files = glob.glob('../data/mobile_elements_sequences_metagenomes/*fasta')\n",
    "# iterating over files\n",
    "for metagenome_fna_file in metagenome_fna_files:\n",
    "    # get metagenome tag\n",
    "    metagenome_tag = metagenome_fna_file.split('/')[3].replace('.fasta', '').lower().split('.')[0]\n",
    "    # appending pandas DataFrame\n",
    "    metagenome_species_data.append(pd.DataFrame.from_dict({'Genome_id': [metagenome_tag], 'Taxonomy': [metagenome_tag]}))\n",
    "metagenome_species_data_table = pd.concat(metagenome_species_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3cc1131e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# opening old file and saving new\n",
    "genome2taxonomy_table = pd.read_csv('../data/genomes_and_taxonomy.csv', sep = ',')\n",
    "# create row for Halovivax\n",
    "halovivax_data_table = pd.DataFrame.from_dict({'Genome_id': ['017357405.1'], 'Taxonomy': ['Halovivax_sp_KZCA124']})\n",
    "# concatenating tables\n",
    "genome2taxonomy_table_full = [genome2taxonomy_table, halovivax_data_table, mag_species_data_table, metagenome_species_data_table]\n",
    "genome2taxonomy_full = pd.concat(genome2taxonomy_table_full)\n",
    "# getting rid of duplicates (in case of re-running script)\n",
    "genome2taxonomy_full = genome2taxonomy_full.drop_duplicates()\n",
    "# saving new table\n",
    "genome2taxonomy_full.loc[:, ['Genome_id', 'Taxonomy']].to_csv('../data/genomes_and_taxonomy.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a9cfdce-48e8-42a4-8e44-6916e2cd59f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genome_id</th>\n",
       "      <th>Taxonomy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1227494.3</td>\n",
       "      <td>Natrinema_altunense_JCM_12890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1526048.3</td>\n",
       "      <td>Haloferax_sp_Q22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222984.5</td>\n",
       "      <td>Natrinema_altunense_strain_AJ2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2496101.3</td>\n",
       "      <td>Haloterrigena_sp_SYSU_A121-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2743089.3</td>\n",
       "      <td>Halobonum_sp_NJ-3-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60847.21</td>\n",
       "      <td>Halogeometricum_borinquense_strain_wsp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>926690.3</td>\n",
       "      <td>Haloplanus_natans_DSM_17983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GCA_011039335.1</td>\n",
       "      <td>Proteobacteria_Candidatus_Desulfofervidus_auxilii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GCA_011380245.1</td>\n",
       "      <td>Thermoproteota_DSZF01_sp011372955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GCA_011358415.1</td>\n",
       "      <td>Micrarchaeota_DTNV01_sp011358415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GCA_011044075.1</td>\n",
       "      <td>Candidatus_Aenigmarchaeota_GCA_011044075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GCA_011042275.1</td>\n",
       "      <td>Altarchaeota_QMZG01_sp003663045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GCA_003641755.1</td>\n",
       "      <td>Thermotogae_GCA_003641755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GCA_003644925.1</td>\n",
       "      <td>Fermentibacterota_Aegiribacteria_sp003644925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GCA_003662775.1</td>\n",
       "      <td>Candidatus_Thorarchaeota_GCA_003662775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GCA_003662005.1</td>\n",
       "      <td>Candidatus_Bathyarchaeota_GCA_003662005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GCA_003661485.1</td>\n",
       "      <td>Candidatus_Geothermarchaeota_GCA_003661485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GCA_000830315.1</td>\n",
       "      <td>Nanoarchaeota_GW2011-AR20_sp000830315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GCA_013152655.1</td>\n",
       "      <td>Bacteroidota_JAADFW01_sp013152655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GCA_012962785.1</td>\n",
       "      <td>Candidatus_Micrarchaeota_GCA_012962785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GCA_012026795.1</td>\n",
       "      <td>Halobacteriota_Methanoperedens_sp012026795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ga0164313_10000250</td>\n",
       "      <td>ga0164313_10000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ga0208375_1000150</td>\n",
       "      <td>ga0208375_1000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ga0075120_10000694</td>\n",
       "      <td>ga0075120_10000694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>jgi12330j12834_1000008</td>\n",
       "      <td>jgi12330j12834_1000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ga0207719_100190</td>\n",
       "      <td>ga0207719_100190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ga0078972_1006503</td>\n",
       "      <td>ga0078972_1006503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ga0222658_1000332</td>\n",
       "      <td>ga0222658_1000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ga0172379_10000243</td>\n",
       "      <td>ga0172379_10000243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ga0222667_1000160</td>\n",
       "      <td>ga0222667_1000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ga0207718_100100</td>\n",
       "      <td>ga0207718_100100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ga0075122_10000827</td>\n",
       "      <td>ga0075122_10000827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ga0172379_10001592</td>\n",
       "      <td>ga0172379_10001592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ga0075122_10000851</td>\n",
       "      <td>ga0075122_10000851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ga0065719_100268</td>\n",
       "      <td>ga0065719_100268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ga0075122_10000557</td>\n",
       "      <td>ga0075122_10000557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ga0207733_100382</td>\n",
       "      <td>ga0207733_100382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ga0207715_100102</td>\n",
       "      <td>ga0207715_100102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ga0172377_10000119</td>\n",
       "      <td>ga0172377_10000119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ga0116200_10000074</td>\n",
       "      <td>ga0116200_10000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>GCA_001563915.1</td>\n",
       "      <td>Nanohaloarchaeota_B1-Br10-U2g21_sp001563915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>017357405.1</td>\n",
       "      <td>Halovivax_sp_KZCA124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Genome_id                                           Taxonomy\n",
       "0                1227494.3                      Natrinema_altunense_JCM_12890\n",
       "1                1526048.3                                   Haloferax_sp_Q22\n",
       "2                 222984.5                     Natrinema_altunense_strain_AJ2\n",
       "3                2496101.3                       Haloterrigena_sp_SYSU_A121-1\n",
       "4                2743089.3                                Halobonum_sp_NJ-3-1\n",
       "5                 60847.21            Halogeometricum_borinquense_strain_wsp4\n",
       "6                 926690.3                        Haloplanus_natans_DSM_17983\n",
       "7          GCA_011039335.1  Proteobacteria_Candidatus_Desulfofervidus_auxilii\n",
       "8          GCA_011380245.1                  Thermoproteota_DSZF01_sp011372955\n",
       "9          GCA_011358415.1                   Micrarchaeota_DTNV01_sp011358415\n",
       "10         GCA_011044075.1           Candidatus_Aenigmarchaeota_GCA_011044075\n",
       "11         GCA_011042275.1                    Altarchaeota_QMZG01_sp003663045\n",
       "12         GCA_003641755.1                          Thermotogae_GCA_003641755\n",
       "13         GCA_003644925.1       Fermentibacterota_Aegiribacteria_sp003644925\n",
       "14         GCA_003662775.1             Candidatus_Thorarchaeota_GCA_003662775\n",
       "15         GCA_003662005.1            Candidatus_Bathyarchaeota_GCA_003662005\n",
       "16         GCA_003661485.1         Candidatus_Geothermarchaeota_GCA_003661485\n",
       "17         GCA_000830315.1              Nanoarchaeota_GW2011-AR20_sp000830315\n",
       "18         GCA_013152655.1                  Bacteroidota_JAADFW01_sp013152655\n",
       "19         GCA_012962785.1             Candidatus_Micrarchaeota_GCA_012962785\n",
       "20         GCA_012026795.1         Halobacteriota_Methanoperedens_sp012026795\n",
       "21      ga0164313_10000250                                 ga0164313_10000250\n",
       "22       ga0208375_1000150                                  ga0208375_1000150\n",
       "23      ga0075120_10000694                                 ga0075120_10000694\n",
       "24  jgi12330j12834_1000008                             jgi12330j12834_1000008\n",
       "25        ga0207719_100190                                   ga0207719_100190\n",
       "26       ga0078972_1006503                                  ga0078972_1006503\n",
       "27       ga0222658_1000332                                  ga0222658_1000332\n",
       "28      ga0172379_10000243                                 ga0172379_10000243\n",
       "29       ga0222667_1000160                                  ga0222667_1000160\n",
       "30        ga0207718_100100                                   ga0207718_100100\n",
       "31      ga0075122_10000827                                 ga0075122_10000827\n",
       "32      ga0172379_10001592                                 ga0172379_10001592\n",
       "33      ga0075122_10000851                                 ga0075122_10000851\n",
       "34        ga0065719_100268                                   ga0065719_100268\n",
       "35      ga0075122_10000557                                 ga0075122_10000557\n",
       "36        ga0207733_100382                                   ga0207733_100382\n",
       "37        ga0207715_100102                                   ga0207715_100102\n",
       "38      ga0172377_10000119                                 ga0172377_10000119\n",
       "39      ga0116200_10000074                                 ga0116200_10000074\n",
       "40         GCA_001563915.1        Nanohaloarchaeota_B1-Br10-U2g21_sp001563915\n",
       "41             017357405.1                               Halovivax_sp_KZCA124"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.drop_duplicates(genome2taxonomy_full.loc[:, ['Genome_id', 'Taxonomy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e897f3e8-ffd4-4d92-98f0-cb5a355f14ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43fc8677-49b8-42d5-adf4-aa925aa24894",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating directories to allocate\n",
    "target_dirs = ['../results/MEs_predicted_orfs_renamed', \n",
    "               '../results/MEs_predicted_orfs_renamed/results', \n",
    "               '../results/MEs_predicted_orfs_renamed/data']\n",
    "\n",
    "[create_dir(dir) for dir in target_dirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5033b02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: ── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.3.1 ──\n",
      "\n",
      "R[write to console]: \u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.3     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.2     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.6\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.3     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.4.0     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n",
      "\n",
      "R[write to console]: ── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘magrittr’\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    set_names\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    extract\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘glue’\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    collapse\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[36m──\u001b[39m \u001b[1m\u001b[1mColumn specification\u001b[1m\u001b[22m \u001b[36m────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[39m\n",
      "cols(\n",
      "  Genome_id = \u001b[31mcol_character()\u001b[39m,\n",
      "  Taxonomy = \u001b[31mcol_character()\u001b[39m\n",
      ")\n",
      "\n",
      "\n",
      "\u001b[36m──\u001b[39m \u001b[1m\u001b[1mColumn specification\u001b[1m\u001b[22m \u001b[36m────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[39m\n",
      "cols(\n",
      "  .default = col_double(),\n",
      "  query_id = \u001b[31mcol_character()\u001b[39m,\n",
      "  subject_id = \u001b[31mcol_character()\u001b[39m\n",
      ")\n",
      "\u001b[36mℹ\u001b[39m Use \u001b[30m\u001b[47m\u001b[30m\u001b[47m`spec()`\u001b[47m\u001b[30m\u001b[49m\u001b[39m for the full column specifications.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R -o orfs_annotation_table\n",
    "\n",
    "# loading libraries\n",
    "library(tidyverse)\n",
    "library(magrittr)\n",
    "library(glue)\n",
    "library(bioseq)\n",
    "library(tidytidbits)\n",
    "\n",
    "# loading table relating species and genome ID\n",
    "genomes_and_taxonomy.tibble = readr::read_csv('../data/genomes_and_taxonomy.csv', col_names = T) %>% dplyr::mutate(Genome_id = Genome_id %>% as.character())\n",
    "genomes_and_taxonomy.dict = genomes_and_taxonomy.tibble$Taxonomy\n",
    "names(genomes_and_taxonomy.dict) = genomes_and_taxonomy.tibble$Genome_id %>% str_replace_all(., 'GCA_', '')\n",
    "\n",
    "# loading genomes and creating a dictionary for contig names and contig code\n",
    "contig_codes_and_labels.tibble = tibble(genome_fasta = list.files('../data/genome_annotations', pattern = '.fna$', full.names = T, recursive = T)) %>%\n",
    "  group_split(genome_fasta) %>%\n",
    "  purrr::map_dfr(., ~{fasta = .x$genome_fasta\n",
    "                  fasta_vct = bioseq::read_fasta(fasta, type = 'DNA') \n",
    "                      \n",
    "                  fasta_vct %>% \n",
    "                      as_tibble() %>%\n",
    "                      dplyr::rename(sequence = 'value') %>%\n",
    "                      dplyr::mutate(label = names(fasta_vct)) %>%\n",
    "                      dplyr::mutate(contig_code = label %>% str_split(' ') %>% purrr::map_chr(1))\n",
    "                  })\n",
    "\n",
    "code2contig.dict = contig_codes_and_labels.tibble$label\n",
    "names(code2contig.dict) = contig_codes_and_labels.tibble$contig_code\n",
    "\n",
    "# loading correspondence between ORFs and annotated features\n",
    "RBH.tibble = readr::read_tsv('../results/MEs_annotated_features_vs_predicted_orfs_BRHs.tsv', col_names = T)\n",
    "annotated2ORF.dict = RBH.tibble$query_id\n",
    "names(annotated2ORF.dict) = RBH.tibble$subject_id\n",
    "\n",
    "# loading ORFs FASTAs\n",
    "orfs_annotation.tibble = tibble(FASTA_file = list.files('../results/MEs_predicted_orfs', pattern = '.faa', full.names = T)) %>%\n",
    "  # stablishing organism code\n",
    "  dplyr::mutate(genome_id = FASTA_file %>% str_split('/') %>% purrr::map_chr(4) %>% str_replace_all(., 'ME.|.predicted_orfs.faa|.MAG|.metagenome', ''),\n",
    "                species_code = genome_id %>% tidytidbits::lookup_chr(., dict = genomes_and_taxonomy.dict)) %>%\n",
    "  # loading FASTAs\n",
    "  group_split(FASTA_file) %>%\n",
    "  purrr::map_dfr(., ~{\n",
    "                 file = .x$FASTA_file\n",
    "                 genome_id = .x$genome_id\n",
    "                 species_code = .x$species_code\n",
    "    \n",
    "                 fasta_vct = bioseq::read_fasta(file, type = 'AA') \n",
    "                 \n",
    "                 fasta_vct %>%\n",
    "                 as_tibble() %>%\n",
    "                 dplyr::mutate(label = names(fasta_vct)) %>%\n",
    "                 dplyr::rename(sequence = 'value') %>%\n",
    "                 # renaming sequences and parsing data related to strandedness, origin and stop\n",
    "                 dplyr::mutate(genome_id = genome_id, \n",
    "                               new_label = glue('ORF_{1:nrow(.)}_{species_code}'),\n",
    "                               annotated_feature_name = label %>% \n",
    "                                  str_split(' ') %>% \n",
    "                                  purrr::map_chr(1) %>% \n",
    "                                  tidytidbits::lookup_chr(., dict = annotated2ORF.dict),\n",
    "                               contig = label %>% str_split(' ') %>% \n",
    "                                  purrr::map_chr(1) %>% \n",
    "                                  str_split('_') %>%\n",
    "                                  purrr::map_chr(., ~{.[-length(.)] %>% paste(collapse = '_')}) %>%\n",
    "                                  tidytidbits::lookup_chr(., dict = code2contig.dict, default = identity),\n",
    "                               strand = case_when(str_detect(label, 'REVERSE') ~ '-', TRUE ~ '+'),\n",
    "                               START = label %>% str_split(' ') %>% purrr::map_chr(2) %>% str_replace_all(., '\\\\[', '') %>% as.double(),\n",
    "                               STOP = label %>% str_split(' ') %>% purrr::map_chr(4) %>% str_replace_all(., '\\\\]', '') %>% as.double())\n",
    "                 }) %>%\n",
    "  dplyr::rename(sequence_AA = 'sequence', `Genome ID` = 'genome_id', `ORF ID` = 'new_label', `Featured ID in Genome Annotation` = 'annotated_feature_name',\n",
    "               `getorf featured ID` = 'label') %>%\n",
    "  dplyr::relocate(., `Genome ID`, `ORF ID`, `Featured ID in Genome Annotation` , `getorf featured ID`, contig, strand, START, STOP, sequence_AA)\n",
    "  \n",
    "# saving table\n",
    "orfs_annotation.tibble %>% dplyr::select(-sequence_AA) %>% readr::write_tsv('../results/MEs_predicted_orfs_renamed/data/annotation_table_ORFs_renamed.tsv', col_names = T)\n",
    "\n",
    "# create table to examine annotation in python\n",
    "orfs_annotation_table = orfs_annotation.tibble "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f4d2d-0770-4aae-927a-c03fdd937b07",
   "metadata": {},
   "source": [
    "# Create MSA for homolog groups \n",
    "Running MAFFT under L-INS-I method for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e04f7963-9208-409d-8bb8-ae96fb67a11e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# script made to align clusters of homologous sequences with MAFFT running under L-INS-I algorithm\n",
    "# import libraries\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "\n",
    "# creating directory to allocate alignments\n",
    "if not os.path.exists('../results/MEs_predicted_orfs_homolog_alns'):\n",
    "  os.mkdir('../results/MEs_predicted_orfs_homolog_alns')\n",
    "\n",
    "# listing homologs groups\n",
    "homolog_groups_data = [(file.replace('.faa', '.msa'),\n",
    "                        file) for file in os.listdir('../results/MEs_predicted_orfs_filtered_homologous_groups') if file.endswith('.faa')]\n",
    "\n",
    "# running alignments\n",
    "for set in homolog_groups_data:\n",
    "  # unpacking variables\n",
    "  msa_output, homolog_cluster_file = set\n",
    "  if not os.path.exists('../results/MEs_predicted_orfs_homolog_alns/{0}'.format(msa_output)):\n",
    "    out_file = open('../results/MEs_predicted_orfs_homolog_alns/{0}'.format(msa_output), 'w') \n",
    "    mafft_command = 'mafft --maxiterate 1000 --localpair ../results/MEs_predicted_orfs_filtered_homologous_groups/{0}'.format(homolog_cluster_file).split(' ')\n",
    "    subprocess.run(mafft_command, stdout = out_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efad2ae",
   "metadata": {},
   "source": [
    "# Perform remote homologs searches for each homolog group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97517a71-25b1-4066-a6af-437949fdd195",
   "metadata": {},
   "source": [
    "## Perform search with *jackhmmer* against UniRef50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a24766a-1fdf-43c8-9953-9343b5f52ba7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results/MEs_predicted_orfs_filtered_homologous_groups/43214_NZ_CP071597.1_1987.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/41684_NZ_CP071597.1_457.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/33690_QNAN01000020.1_20.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/41631_NZ_CP071597.1_404.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/43868_NZ_CP071597.1_2641.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/43865_NZ_CP071597.1_2638.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/43833_NZ_CP071597.1_2606.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/47161_JNCS01000001_1324.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/43797_NZ_CP071597.1_2570.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/41611_NZ_CP071597.1_384.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/44824_LOEP01000012_734.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/42776_NZ_CP071597.1_1549.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/43810_NZ_CP071597.1_2583.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/42763_NZ_CP071597.1_1536.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/47260_JNCS01000001_1423.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/44058_NZ_CP071597.1_2831.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/45346_LOEP01000012_1256.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/45358_LOEP01000012_1268.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/47247_JNCS01000001_1410.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/41756_NZ_CP071597.1_529.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/43248_NZ_CP071597.1_2021.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/44873_LOEP01000012_783.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/45323_LOEP01000012_1233.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/48048_JNCS01000001_2211.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/45263_LOEP01000012_1173.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/35093_QNDS01000002.1_1132.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/33803_QNAN01000020.1_133.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/48076_JNCS01000001_2239.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/45290_LOEP01000012_1200.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/43002_NZ_CP071597.1_1775.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/47154_JNCS01000001_1317.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/47667_JNCS01000001_1830.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/45204_LOEP01000012_1114.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/44905_LOEP01000012_815.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/45253_LOEP01000012_1163.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/45254_LOEP01000012_1164.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/45611_LOEP01000012_1521.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/45237_LOEP01000012_1147.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/45230_LOEP01000012_1140.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/47589_JNCS01000001_1752.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/45297_LOEP01000012_1207.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/33768_QNAN01000020.1_98.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/43895_NZ_CP071597.1_2668.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/33779_QNAN01000020.1_109.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/33744_QNAN01000020.1_74.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/33726_QNAN01000020.1_56.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/44970_LOEP01000012_880.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/33694_QNAN01000020.1_24.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/42988_NZ_CP071597.1_1761.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/44169_LOEP01000012_79.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/33763_QNAN01000020.1_93.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/33821_QNAN01000020.1_151.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/44950_LOEP01000012_860.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/33781_QNAN01000020.1_111.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/43720_NZ_CP071597.1_2493.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/33021_LKMP01000007.1_947.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/47835_JNCS01000001_1998.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/33758_QNAN01000020.1_88.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/44961_LOEP01000012_871.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/42832_NZ_CP071597.1_1605.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/43027_NZ_CP071597.1_1800.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/60120_ATYM01000002_1457.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/39872_VEPM01000029.1_1392.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/48320_JNCS01000001_2483.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/56537_CP048739_306.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/48014_JNCS01000001_2177.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/64660_Ga0075122_10000557_495.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/45209_LOEP01000012_1119.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/48293_JNCS01000001_2456.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/60136_ATYM01000002_1473.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/48377_JNCS01000001_2540.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/48350_JNCS01000001_2513.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/33720_QNAN01000020.1_50.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/64551_Ga0075122_10000557_386.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/33757_QNAN01000020.1_87.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/67914_Ga0078972_1006503_844.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/45475_LOEP01000012_1385.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/59235_ATYM01000002_572.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37916_DRYJ01000053.1_438.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37951_DRYJ01000053.1_473.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/36484_DQXS01000079.1_213.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/42794_NZ_CP071597.1_1567.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37592_DRYJ01000053.1_114.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34263_QNDS01000002.1_302.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/36583_DQXS01000079.1_312.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/84209_Ga0207718_100100_2261.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/53221_CP058579_1779.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/52581_CP058579_1139.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34285_QNDS01000002.1_324.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37946_DRYJ01000053.1_468.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37778_DRYJ01000053.1_300.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/4668_CP010426.1_4668.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34439_QNDS01000002.1_478.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/91810_Ga0222658_1000332_677.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37602_DRYJ01000053.1_124.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/57516_CP048739_1285.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/44419_LOEP01000012_329.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/42018_NZ_CP071597.1_791.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/83409_Ga0207718_100100_1461.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/71266_Ga0172377_10000119_869.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/16193_CP010426.1_16193.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/82800_Ga0207718_100100_852.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/47706_JNCS01000001_1869.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/91184_Ga0222658_1000332_51.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/71396_Ga0172377_10000119_999.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/55853_CP058579_4411.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/51382_JABURA010000001_2811.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/35342_QNDS01000002.1_1381.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/64497_Ga0075122_10000557_332.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37502_DRYJ01000053.1_24.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37515_DRYJ01000053.1_37.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/71369_Ga0172377_10000119_972.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34174_QNDS01000002.1_213.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34099_QNDS01000002.1_138.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/71282_Ga0172377_10000119_885.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/36659_DQXS01000079.1_388.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/71288_Ga0172377_10000119_891.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/44177_LOEP01000012_87.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37809_DRYJ01000053.1_331.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/83860_Ga0207718_100100_1912.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/38326_DRYJ01000053.1_848.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/91260_Ga0222658_1000332_127.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/53296_CP058579_1854.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34221_QNDS01000002.1_260.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37736_DRYJ01000053.1_258.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/65223_Ga0075122_10000557_1058.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/11406_CP010426.1_11406.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/9663_CP010426.1_9663.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/65193_Ga0075122_10000557_1028.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/91289_Ga0222658_1000332_156.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/33966_QNDS01000002.1_5.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/82267_Ga0207718_100100_319.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/83636_Ga0207718_100100_1688.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/91205_Ga0222658_1000332_72.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/44437_LOEP01000012_347.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/41701_NZ_CP071597.1_474.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/35679_QMYS01000134.1_102.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/48065_JNCS01000001_2228.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/91803_Ga0222658_1000332_670.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37940_DRYJ01000053.1_462.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/35350_QNDS01000002.1_1389.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/84146_Ga0207718_100100_2198.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/82926_Ga0207718_100100_978.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/48400_JNCS01000001_2563.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/26612_CP010426.1_26612.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/71306_Ga0172377_10000119_909.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/60477_ATYM01000002_1814.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34321_QNDS01000002.1_360.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/53312_CP058579_1870.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/85534_Ga0207719_100190_852.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37509_DRYJ01000053.1_31.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/83645_Ga0207718_100100_1697.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37841_DRYJ01000053.1_363.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34553_QNDS01000002.1_592.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/11192_CP010426.1_11192.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/64190_Ga0075122_10000557_25.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/59096_ATYM01000002_433.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/71526_Ga0172377_10000119_1129.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/43488_NZ_CP071597.1_2261.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/75133_Ga0172379_10000243_2138.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/21986_CP010426.1_21986.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34093_QNDS01000002.1_132.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34428_QNDS01000002.1_467.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/84261_Ga0207718_100100_2313.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/35326_QNDS01000002.1_1365.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/36544_DQXS01000079.1_273.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/44027_NZ_CP071597.1_2800.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/46941_JNCS01000001_1104.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/43381_NZ_CP071597.1_2154.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/44441_LOEP01000012_351.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/82806_Ga0207718_100100_858.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37806_DRYJ01000053.1_328.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/71412_Ga0172377_10000119_1015.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/35068_QNDS01000002.1_1107.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37956_DRYJ01000053.1_478.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/10196_CP010426.1_10196.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37579_DRYJ01000053.1_101.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/36624_DQXS01000079.1_353.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/2409_CP010426.1_2409.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/44002_NZ_CP071597.1_2775.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34029_QNDS01000002.1_68.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37767_DRYJ01000053.1_289.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/91305_Ga0222658_1000332_172.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/50067_JABURA010000001_1496.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37795_DRYJ01000053.1_317.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/43290_NZ_CP071597.1_2063.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/53246_CP058579_1804.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/64443_Ga0075122_10000557_278.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/36520_DQXS01000079.1_249.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/46092_JNCS01000001_255.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/46412_JNCS01000001_575.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/85783_Ga0207719_100190_1101.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/35360_QNDS01000002.1_1399.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34548_QNDS01000002.1_587.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/71319_Ga0172377_10000119_922.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/85990_Ga0207719_100190_1308.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/35334_QNDS01000002.1_1373.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/53883_CP058579_2441.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34116_QNDS01000002.1_155.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/36609_DQXS01000079.1_338.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/84302_Ga0207718_100100_2354.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/31041_CP010426.1_31041.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34729_QNDS01000002.1_768.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34034_QNDS01000002.1_73.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/84632_Ga0207718_100100_2684.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/82375_Ga0207718_100100_427.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/91317_Ga0222658_1000332_184.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/47195_JNCS01000001_1358.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/91362_Ga0222658_1000332_229.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37817_DRYJ01000053.1_339.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/91194_Ga0222658_1000332_61.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/36425_DQXS01000079.1_154.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/85158_Ga0207719_100190_476.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/36597_DQXS01000079.1_326.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/84155_Ga0207718_100100_2207.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/46764_JNCS01000001_927.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/36613_DQXS01000079.1_342.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34044_QNDS01000002.1_83.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/36629_DQXS01000079.1_358.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37490_DRYJ01000053.1_12.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/82677_Ga0207718_100100_729.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/71437_Ga0172377_10000119_1040.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/48625_JABURA010000001_54.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/91292_Ga0222658_1000332_159.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/41717_NZ_CP071597.1_490.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/36591_DQXS01000079.1_320.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34255_QNDS01000002.1_294.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/65217_Ga0075122_10000557_1052.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/91349_Ga0222658_1000332_216.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34147_QNDS01000002.1_186.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/35352_QNDS01000002.1_1391.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/36510_DQXS01000079.1_239.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/42908_NZ_CP071597.1_1681.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37801_DRYJ01000053.1_323.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/46442_JNCS01000001_605.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37606_DRYJ01000053.1_128.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37739_DRYJ01000053.1_261.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/74969_Ga0172379_10000243_1974.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/36620_DQXS01000079.1_349.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37513_DRYJ01000053.1_35.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/84608_Ga0207718_100100_2660.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/38001_DRYJ01000053.1_523.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/57534_CP048739_1303.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/50165_JABURA010000001_1594.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37615_DRYJ01000053.1_137.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/84018_Ga0207718_100100_2070.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/82702_Ga0207718_100100_754.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/43338_NZ_CP071597.1_2111.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/53268_CP058579_1826.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/41728_NZ_CP071597.1_501.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/19531_CP010426.1_19531.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34188_QNDS01000002.1_227.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/84024_Ga0207718_100100_2076.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/53204_CP058579_1762.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/46404_JNCS01000001_567.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/49964_JABURA010000001_1393.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34056_QNDS01000002.1_95.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34669_QNDS01000002.1_708.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/54484_CP058579_3042.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/64534_Ga0075122_10000557_369.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34211_QNDS01000002.1_250.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/41735_NZ_CP071597.1_508.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34051_QNDS01000002.1_90.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/91816_Ga0222658_1000332_683.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/82877_Ga0207718_100100_929.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/53178_CP058579_1736.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/91178_Ga0222658_1000332_45.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37968_DRYJ01000053.1_490.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37781_DRYJ01000053.1_303.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/44183_LOEP01000012_93.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/91297_Ga0222658_1000332_164.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34259_QNDS01000002.1_298.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/71345_Ga0172377_10000119_948.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/39559_VEPM01000029.1_1079.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/36579_DQXS01000079.1_308.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/48610_JABURA010000001_39.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34515_QNDS01000002.1_554.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37834_DRYJ01000053.1_356.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34290_QNDS01000002.1_329.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/71279_Ga0172377_10000119_882.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/46496_JNCS01000001_659.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/82354_Ga0207718_100100_406.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/40171_VEPM01000029.1_1691.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/64485_Ga0075122_10000557_320.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34461_QNDS01000002.1_500.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37924_DRYJ01000053.1_446.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/36571_DQXS01000079.1_300.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/91345_Ga0222658_1000332_212.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34047_QNDS01000002.1_86.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34077_QNDS01000002.1_116.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/45840_JNCS01000001_3.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/43826_NZ_CP071597.1_2599.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/65220_Ga0075122_10000557_1055.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37787_DRYJ01000053.1_309.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/52836_CP058579_1394.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37811_DRYJ01000053.1_333.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/43074_NZ_CP071597.1_1847.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/51369_JABURA010000001_2798.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/50275_JABURA010000001_1704.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/47658_JNCS01000001_1821.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34085_QNDS01000002.1_124.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34542_QNDS01000002.1_581.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34472_QNDS01000002.1_511.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/81560_Ga0207715_100102_1072.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/65181_Ga0075122_10000557_1016.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/82852_Ga0207718_100100_904.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/53252_CP058579_1810.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/12736_CP010426.1_12736.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34062_QNDS01000002.1_101.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/85853_Ga0207719_100190_1171.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/35037_QNDS01000002.1_1076.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/71661_Ga0172377_10000119_1264.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34166_QNDS01000002.1_205.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/71415_Ga0172377_10000119_1018.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/72488_Ga0172377_10000119_2091.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/71591_Ga0172377_10000119_1194.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/45855_JNCS01000001_18.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/28814_CP010426.1_28814.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34522_QNDS01000002.1_561.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37934_DRYJ01000053.1_456.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34455_QNDS01000002.1_494.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/63249_Ga0075120_10000694_187.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/57495_CP048739_1264.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/50027_JABURA010000001_1456.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37583_DRYJ01000053.1_105.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/19511_CP010426.1_19511.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/82396_Ga0207718_100100_448.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/91266_Ga0222658_1000332_133.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/84204_Ga0207718_100100_2256.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/45247_LOEP01000012_1157.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/91341_Ga0222658_1000332_208.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/44447_LOEP01000012_357.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/36563_DQXS01000079.1_292.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/80619_Ga0207715_100102_131.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37570_DRYJ01000053.1_92.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37540_DRYJ01000053.1_62.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/91277_Ga0222658_1000332_144.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/72765_Ga0172377_10000119_2368.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/82954_Ga0207718_100100_1006.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34243_QNDS01000002.1_282.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37975_DRYJ01000053.1_497.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/46341_JNCS01000001_504.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/42813_NZ_CP071597.1_1586.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/85521_Ga0207719_100190_839.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/71434_Ga0172377_10000119_1037.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/64182_Ga0075122_10000557_17.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/71594_Ga0172377_10000119_1197.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/83458_Ga0207718_100100_1510.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/36588_DQXS01000079.1_317.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/37844_DRYJ01000053.1_366.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/64173_Ga0075122_10000557_8.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34072_QNDS01000002.1_111.faa\n",
      "../results/MEs_predicted_orfs_filtered_homologous_groups/34194_QNDS01000002.1_233.faa\n"
     ]
    }
   ],
   "source": [
    "# script made to extend groups of homologues already found with distant homolog searches\n",
    "# importing libaries\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from io import StringIO\n",
    "from collections import defaultdict\n",
    "from Bio import SearchIO\n",
    "import urllib\n",
    "\n",
    "# loading table of homologous groups founded, and getting those with more than two sequences\n",
    "homolog_groups_with_ORFs_table = pd.read_csv('../results/homolog_groups_tables/homolog_groups_with_ORFs.tsv', sep = '\\t')\n",
    "\n",
    "# creating directory to allocate files created in this script\n",
    "dirs_to_be_created = ['../results/homolog_groups_expansion_and_collapse/results/jackhmmer_hits_fastas',\n",
    "                      '../results/homolog_groups_expansion_and_collapse/results/jackhmmerouts',\n",
    "                      '../results/homolog_groups_expansion_and_collapse/results/jackhmmeralns',\n",
    "                      '../results/homolog_groups_expansion_and_collapse/results/jackhmmertblouts',\n",
    "                      '../results/homolog_groups_expansion_and_collapse/results/jackhmmerdomtblouts',\n",
    "                      '../results/homolog_groups_expansion_and_collapse/results/jackhmmerhmms',\n",
    "                      '../results/homolog_groups_expansion_and_collapse/results/jackhmmer_hits_alns',\n",
    "                      '../results/homolog_groups_expansion_and_collapse/results/homolog_groups_HMMs',\n",
    "                      '../results/homolog_groups_expansion_and_collapse/results/hmmsearch_results',\n",
    "                      '../results/homolog_groups_expansion_and_collapse/results/hmmsearch_results/hmmsearchouts',\n",
    "                      '../results/homolog_groups_expansion_and_collapse/results/hmmsearch_results/tblouts',\n",
    "                      '../results/homolog_groups_expansion_and_collapse/results/hmmsearch_results/domtblouts']\n",
    "\n",
    "for dir in dirs_to_be_created:\n",
    "  if not os.path.exists(dir):\n",
    "    os.mkdir(dir)\n",
    "    \n",
    "# running jackhmmer with fasta files\n",
    "for fasta_file in homolog_groups_with_ORFs_table.File.to_list():\n",
    "  if os.path.exists(fasta_file):\n",
    "    # getting tag of group\n",
    "    tag = fasta_file.split('/')[3].replace('.faa', '')\n",
    "    database = '../../../../databases/uniref50.fasta'\n",
    "    # running with 1 iterations\n",
    "    if not os.path.exists('../results/homolog_groups_expansion_and_collapse/results/jackhmmerouts/{0}.jackhmmer.out'.format(tag)):\n",
    "      command = 'jackhmmer -N 1 -o ../results/homolog_groups_expansion_and_collapse/results/jackhmmerouts/{0}.jackhmmer.out -A ../results/homolog_groups_expansion_and_collapse/results/jackhmmeralns/{0}.jackhmmer.aln --tblout ../results/homolog_groups_expansion_and_collapse/results/jackhmmertblouts/{0}.tblout --domtblout ../results/homolog_groups_expansion_and_collapse/results/jackhmmerdomtblouts/{0}.domblout --chkhmm ../results/homolog_groups_expansion_and_collapse/results/jackhmmerhmms/{0}.hmms --cpu 15 {1} {2}'.format(tag, fasta_file, database).split(' ')\n",
    "      # run jackhmmer\n",
    "      subprocess.run(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceceea7-83fd-4efd-9fd2-0b8073921b81",
   "metadata": {},
   "source": [
    "## Tabulation of *jackhmmer* results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8546246d-9128-4dd2-8832-352972e05523",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|====================================================================| 100% 7 MB\n"
     ]
    }
   ],
   "source": [
    "%%R \n",
    "# script made to tabulate some domtblouts tables generated with jackhmmer3\n",
    "# loading libraries\n",
    "library(rhmmer)\n",
    "library(tidyverse)\n",
    "library(glue)\n",
    "library(magrittr)\n",
    "\n",
    "# define column names, as the package assumes headers different from what is actually written in the files\n",
    "domtblouts_colnames = c('target_name', 't_accession', 'tlen', 'query_name', 'q_accession', 'qlen',\n",
    "                    'fullseq_evalue', 'fullseq_score', 'fullseq_bias', 'num_of_domain', 'total_hit_domains', \n",
    "                    'c-evalue', 'i-evalue', 'hmm_score', 'hmm_bias', 'hmm_coord_from', 'hmm_coord_to', 'ali_coord_from',\n",
    "                    'ali_coord_to', 'env_coord_from', 'env_coord_to', 'acc', 'description_of_target')\n",
    "\n",
    "# listing domtblouts files\n",
    "domtblout_files = list.files('../results/homolog_groups_expansion_and_collapse/results/jackhmmerdomtblouts', pattern = '.domblout', full.names = T)\n",
    "\n",
    "# iterating over files and creating output files\n",
    "for (i in seq_along(domtblout_files)) {\n",
    "  # reading file\n",
    "  current_domtblout.tibble = rhmmer::read_domtblout(file = domtblout_files[i])\n",
    "  \n",
    "  # changing column names\n",
    "  colnames(current_domtblout.tibble) = domtblouts_colnames\n",
    "  \n",
    "  # getting file tag\n",
    "  group_tag = domtblout_files[i] %>% str_split('/') %>% purrr::map_chr(6)\n",
    "  \n",
    "  # filtering based on target and query lengths, evalues and query coverage of alignment\n",
    "  # then exporting TSV\n",
    "  \n",
    "  # export the original table\n",
    "  current_domtblout.tibble %>% readr::write_tsv(glue('../results/homolog_groups_expansion_and_collapse/results/jackhmmerdomtblouts_tsvs/{group_tag}.tsv'), col_names = T)\n",
    "  \n",
    "  # export filtered tables\n",
    "  current_domtblout.tibble %>%\n",
    "    # target must have at least 300aa and be no more than 1.5 times the query length\n",
    "    dplyr::filter((100 < tlen) & (tlen <= qlen*1.5)) %>%\n",
    "    rowwise() %>%\n",
    "    # creating column with alignment length and getting qcov\n",
    "    dplyr::mutate(aln_length = abs(ali_coord_to - ali_coord_from),\n",
    "                  qcov = aln_length/qlen) %>%\n",
    "    # query coverage must be at least 50%\n",
    "    dplyr::filter(qcov >= 0.5) %>%\n",
    "    # global sequence e-value must be at most 1e-15\n",
    "    dplyr::filter(fullseq_evalue <= 1e-15) %>%\n",
    "    # saving table\n",
    "    readr::write_tsv(glue('../results/homolog_groups_expansion_and_collapse/results/jackhmmerdomtblouts_tsvs/{group_tag}.filtered.tsv'), col_names = T)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48df446c-6cab-47e1-ab6a-6f95f976fc6d",
   "metadata": {},
   "source": [
    "## Following with remote homology inference (hmmsearch stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "894291d0-dc41-4eb3-919a-cb3c79972816",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# script made to extend groups of homologues already found with distant homolog searches\n",
    "# importing libaries\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from io import StringIO\n",
    "from collections import defaultdict\n",
    "from Bio import SearchIO\n",
    "import urllib\n",
    "\n",
    "# loading table of homologous groups founded, and getting those with more than two sequences\n",
    "homolog_groups_with_ORFs_table = pd.read_csv('../results/homolog_groups_tables/homolog_groups_with_ORFs.tsv', sep = '\\t')\n",
    "\n",
    "# creating directory to allocate files created in this script\n",
    "dirs_to_be_created = ['../results/homolog_groups_expansion_and_collapse/results/jackhmmer_hits_fastas',\n",
    "                      '../results/homolog_groups_expansion_and_collapse/results/jackhmmer_hits_alns',\n",
    "                      '../results/homolog_groups_expansion_and_collapse/results/homolog_groups_HMMs',\n",
    "                      '../results/homolog_groups_expansion_and_collapse/results/hmmsearch_results',\n",
    "                      '../results/homolog_groups_expansion_and_collapse/results/hmmsearch_results/hmmsearchouts',\n",
    "                      '../results/homolog_groups_expansion_and_collapse/results/hmmsearch_results/tblouts',\n",
    "                      '../results/homolog_groups_expansion_and_collapse/results/hmmsearch_results/domtblouts']\n",
    "\n",
    "for dir in dirs_to_be_created:\n",
    "  if not os.path.exists(dir):\n",
    "    os.mkdir(dir)\n",
    "    \n",
    "# getting ORF sequences\n",
    "orfs_set = [(orfs_file.split('/')[3].replace('ME.', '').replace('.fna', ''),\n",
    "               orfs_file) for orfs_file in glob.glob('../results/MEs_predicted_orfs/ME.*')]\n",
    "\n",
    "# loading ORFs with SeqIO.parse\n",
    "orfs_dict = {}\n",
    "for data_set in orfs_set:\n",
    "  # unpacking variables\n",
    "  genome_tag, orfs_file = data_set\n",
    "  genome = SeqIO.parse(orfs_file, 'fasta')\n",
    "  # creating dictionary with sequences, descriptions and genome code\n",
    "  genome_dict = {}\n",
    "  for seq in genome:\n",
    "    orfs_dict.update({seq.name: seq})\n",
    "\n",
    "# saving ORFs in FASTA\n",
    "if not os.path.exists('../results/homolog_groups_expansion_and_collapse/data/all_predicted_orfs.faa'):\n",
    "  with open('../results/homolog_groups_expansion_and_collapse/data/all_predicted_orfs.faa', \"w\") as output_handle:\n",
    "      SeqIO.write(list(orfs_dict.values()), output_handle, \"fasta\")\n",
    "    \n",
    "# iterating over files of domtblouts of jackhmmer and performing\n",
    "list_domtblouts_filtered = glob.glob('../results/homolog_groups_expansion_and_collapse/results/jackhmmerdomtblouts_tsvs/*filtered.tsv')\n",
    "\n",
    "# getting all hits\n",
    "all_uniref50_hits = []\n",
    "for domtblout_file in list_domtblouts_filtered:\n",
    "  # reading table\n",
    "  domtblout_table = pd.read_csv(domtblout_file, sep = '\\t', comment = '#')\n",
    "  # getting hits\n",
    "  hits = domtblout_table.target_name.to_list()\n",
    "  # appending hits\n",
    "  for hit in hits:\n",
    "    all_uniref50_hits.append(hit)\n",
    "\n",
    "#all_uniref50_hits = list(set(all_uniref50_hits))\n",
    "all_uniref50_hits = list(dict.fromkeys(all_uniref50_hits))\n",
    "# saving FASTA file\n",
    "output_fasta_uniref50filtered = '../results/homolog_groups_expansion_and_collapse/data/uniref50_hitted_entries.faa'\n",
    "if not os.path.exists(output_fasta_uniref50filtered):\n",
    "  # subsetting UniRef50 FASTA in order to create a FASTA containing only UniRef hits (in order to subset it in the future)\n",
    "  uniref50_fasta = SeqIO.parse('../../../../databases/uniref50.fasta', 'fasta')\n",
    "  \n",
    "  uniref50_hitted = {}\n",
    "  while len(uniref50_hitted) < len(all_uniref50_hits):\n",
    "    for record in uniref50_fasta:\n",
    "      if record.id in all_uniref50_hits:\n",
    "        print('adding', record.id)\n",
    "        uniref50_hitted.update({record.id: record})\n",
    "\n",
    "  with open(output_fasta_uniref50filtered, \"w\") as output_handle:\n",
    "    SeqIO.write(list(uniref50_hitted.values()), output_handle, \"fasta\")\n",
    "\n",
    "if os.path.exists(output_fasta_uniref50filtered):\n",
    "  # load fasta\n",
    "  uniref50_hitted_fasta = SeqIO.parse(output_fasta_uniref50filtered, 'fasta')\n",
    "  # create dictionary uniref50_hitted\n",
    "  uniref50_hitted = {}\n",
    "  [uniref50_hitted.update({record.id: record}) for record in uniref50_hitted_fasta]\n",
    "    \n",
    "for filename in list_domtblouts_filtered:\n",
    "  # to create the script, an example # filename = '../results/homolog_groups_expansion_and_collapse/results/jackhmmerdomtblouts_tsvs/10721_CP048739_181.domblout.filtered.tsv'\n",
    "  #group_tag = filename.split('/')[5].split('.')[0]\n",
    "  group_tag = filename.split('/')[5].replace('.domblout.filtered.tsv', '')\n",
    "\n",
    "  colnames_domblout = ['target_name', 't_accession', 'tlen', 'query_name', 'q_accession', 'qlen',\n",
    "                      'fullseq_evalue', 'fullseq_score', 'fullseq_bias', 'num_of_domain', 'total_hit_domains', \n",
    "                      'c-evalue', 'i-evalue', 'hmm_score', 'hmm_bias', 'hmm_coord_from', 'hmm_coord_to', 'ali_coord_from',\n",
    "                      'ali_coord_to', 'env_coord_from', 'env_coord_to', 'acc', 'description_of_target', 'aln_length', 'qcov']\n",
    "  \n",
    "  group_jackhmmer_domtable = pd.read_csv(filename, \n",
    "                                         sep = '\\t', \n",
    "                                         comment = '#')\n",
    "  \n",
    "  # getting sequences from UniRef50 and from ORF files\n",
    "  set_of_seqs_dict = {}\n",
    "  \n",
    "  # getting sequences from ORFs in the group\n",
    "  #orfs_in_group = set(group_jackhmmer_domtable.query_name.to_list())\n",
    "  # loading fasta of group\n",
    "  group_fasta = SeqIO.parse('../results/MEs_predicted_orfs_filtered_homologous_groups/{0}.faa'.format(group_tag), 'fasta')\n",
    "  orfs_in_group = [record.id for record in group_fasta]\n",
    "  for orf_id in orfs_in_group:\n",
    "    # retrieve from orf dictionary and appending record\n",
    "    set_of_seqs_dict.update({orf_id: orfs_dict[orf_id]})\n",
    "      \n",
    "  # creating set variable with IDs of hits from UniRef50\n",
    "  #uniref50_hits = set(group_jackhmmer_domtable.target_name.to_list())\n",
    "  uniref50_hits = list(dict.fromkeys((group_jackhmmer_domtable.target_name.to_list())))\n",
    "  \n",
    "  # retrieving with the UniRef API\n",
    "  for uniref_id in uniref50_hits:\n",
    "    # retrieving sequences from uniref50_hitted and appending to set_of_seqs_dict\n",
    "    [set_of_seqs_dict.update({record.id: record}) for record in [uniref50_hitted[uniref_id]]]\n",
    "    \n",
    "  # saving group FASTA into a file\n",
    "  output_fasta_file = '../results/homolog_groups_expansion_and_collapse/results/jackhmmer_hits_fastas/{0}.group_members_and_jackhmmerhits.faa'.format(group_tag)\n",
    "  if not os.path.exists(output_fasta_file):\n",
    "    with open(output_fasta_file, \"w\") as output_handle:\n",
    "      SeqIO.write(list(set_of_seqs_dict.values()), output_handle, \"fasta\")\n",
    "      \n",
    "  # aligning sequences based on HMM profile\n",
    "  hit_aln = '../results/homolog_groups_expansion_and_collapse/results/jackhmmer_hits_alns/{0}.msa'.format(group_tag)\n",
    "  #hmm_group_jackhmmer = '../results/homolog_groups_expansion_and_collapse/results/jackhmmerhmms/{0}.hmms-1.hmm'.format(group_tag)\n",
    "  if not os.path.exists(hit_aln):\n",
    "    # running hmmalign\n",
    "    #hmmalign_cmd = 'hmmalign -o {0} {1} {2}'.format(hit_aln, hmm_group_jackhmmer, output_fasta_file).split(' ')\n",
    "    #subprocess.run(hmmalign_cmd)\n",
    "    # running MAFFT\n",
    "    out_file = open(hit_aln, 'w') \n",
    "    mafft_command = 'mafft --auto {0}'.format(output_fasta_file).split(' ')\n",
    "    subprocess.run(mafft_command, stdout = out_file)\n",
    "    \n",
    "  # creating new profile\n",
    "  homolog_group_hmmout = '../results/homolog_groups_expansion_and_collapse/results/homolog_groups_HMMs/{0}.hmm'.format(group_tag)\n",
    "  if not os.path.exists(homolog_group_hmmout):\n",
    "    hmmbuild_cmd = 'hmmbuild --cpu 3 {0} {1}'.format(homolog_group_hmmout, hit_aln).split(' ')\n",
    "    subprocess.run(hmmbuild_cmd)\n",
    "  \n",
    "  # searching against ORFs with hmmsearch\n",
    "  hmmsearchout = '../results/homolog_groups_expansion_and_collapse/results/hmmsearch_results/hmmsearchouts/{0}.hmmsearchout'.format(group_tag)\n",
    "  hmmsearchtblout = '../results/homolog_groups_expansion_and_collapse/results/hmmsearch_results/tblouts/{0}.tblout'.format(group_tag)\n",
    "  hmmsearchdomtblout = '../results/homolog_groups_expansion_and_collapse/results/hmmsearch_results/domtblouts/{0}.domtblout'.format(group_tag)\n",
    "  if not os.path.exists(hmmsearchout):\n",
    "    hmmsearch_cmd = 'hmmsearch -o {0} --tblout {1} --domtblout {2} --cpu 3 {3} ../results/homolog_groups_expansion_and_collapse/data/all_predicted_orfs.faa'.format(hmmsearchout, hmmsearchtblout, hmmsearchdomtblout, homolog_group_hmmout, ).split(' ')\n",
    "    subprocess.run(hmmsearch_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6994c584-95de-42c9-ac66-73e04704c300",
   "metadata": {},
   "source": [
    "## Parsing of tabulated *hmmsearch*'s results table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2548a69c-5853-4007-9cef-2c95cc1deadf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 1,404 x 25\u001b[39m\n",
      "\u001b[90m# Rowwise: \u001b[39m\n",
      "   target_name   t_accession  tlen query_name   q_accession  qlen fullseq_evalue\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m CP010426.1_1… -              53 10196_CP010… -              53       1.3\u001b[90me\u001b[39m\u001b[31m- 37\u001b[39m\n",
      "\u001b[90m 2\u001b[39m CP058579_203  -              47 10196_CP010… -              53       1.9\u001b[90me\u001b[39m\u001b[31m- 29\u001b[39m\n",
      "\u001b[90m 3\u001b[39m CP010426.1_1… -             111 11192_CP010… -             123       1.6\u001b[90me\u001b[39m\u001b[31m- 42\u001b[39m\n",
      "\u001b[90m 4\u001b[39m LKMP01000007… -             117 11192_CP010… -             123       8  \u001b[90me\u001b[39m\u001b[31m- 29\u001b[39m\n",
      "\u001b[90m 5\u001b[39m Ga0207715_10… -             421 11406_CP010… -             394       2.1\u001b[90me\u001b[39m\u001b[31m-139\u001b[39m\n",
      "\u001b[90m 6\u001b[39m CP010426.1_1… -             398 11406_CP010… -             394       3.8\u001b[90me\u001b[39m\u001b[31m-136\u001b[39m\n",
      "\u001b[90m 7\u001b[39m VEPM01000029… -             122 12736_CP010… -             112       1.2\u001b[90me\u001b[39m\u001b[31m- 41\u001b[39m\n",
      "\u001b[90m 8\u001b[39m CP010426.1_1… -              98 12736_CP010… -             112       4.9\u001b[90me\u001b[39m\u001b[31m- 33\u001b[39m\n",
      "\u001b[90m 9\u001b[39m CP010426.1_1… -             174 16193_CP010… -             208       1.3\u001b[90me\u001b[39m\u001b[31m- 49\u001b[39m\n",
      "\u001b[90m10\u001b[39m Ga0172379_10… -             208 16193_CP010… -             208       1.5\u001b[90me\u001b[39m\u001b[31m- 48\u001b[39m\n",
      "\u001b[90m# … with 1,394 more rows, and 18 more variables: fullseq_score <dbl>,\u001b[39m\n",
      "\u001b[90m#   fullseq_bias <dbl>, num_of_domain <int>, total_hit_domains <int>,\u001b[39m\n",
      "\u001b[90m#   c-evalue <dbl>, i-evalue <dbl>, hmm_score <dbl>, hmm_bias <dbl>,\u001b[39m\n",
      "\u001b[90m#   hmm_coord_from <int>, hmm_coord_to <int>, ali_coord_from <int>,\u001b[39m\n",
      "\u001b[90m#   ali_coord_to <int>, env_coord_from <int>, env_coord_to <int>, acc <dbl>,\u001b[39m\n",
      "\u001b[90m#   description_of_target <chr>, aln_length <int>, qcov <dbl>\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "%%R \n",
    "# script made to parse hmmsearch results of homologous groups against ORFs\n",
    "# loading libraries\n",
    "library(rhmmer)\n",
    "library(tidyverse)\n",
    "library(magrittr)\n",
    "library(glue)\n",
    "\n",
    "# create vector with column names of hmmsearch output\n",
    "domtblouts_colnames = c('target_name', 't_accession', 'tlen', 'query_name', 'q_accession', 'qlen',\n",
    "                    'fullseq_evalue', 'fullseq_score', 'fullseq_bias', 'num_of_domain', 'total_hit_domains', \n",
    "                    'c-evalue', 'i-evalue', 'hmm_score', 'hmm_bias', 'hmm_coord_from', 'hmm_coord_to', 'ali_coord_from',\n",
    "                    'ali_coord_to', 'env_coord_from', 'env_coord_to', 'acc', 'description_of_target')\n",
    "\n",
    "# see how many hits has each homologous group\n",
    "filtered_hits.tibble = list.files('../results/homolog_groups_expansion_and_collapse/results/hmmsearch_results/domtblouts', pattern = '.domtblout', full.names=T) %>%\n",
    "  as.list() %>%\n",
    "  purrr::map_dfr(., ~{\n",
    "    # load results\n",
    "    current_domtblout.tibble = rhmmer::read_domtblout(file = .x)\n",
    "    # rename columns\n",
    "    colnames(current_domtblout.tibble) = domtblouts_colnames\n",
    "    # filtering results\n",
    "    current_domtblout.tibble %>%\n",
    "      # target must have at least 300aa and be no more than 1.5 times the query length\n",
    "      #dplyr::filter((0.5*qlen < tlen) & (tlen <= qlen*1.5)) %>%\n",
    "      rowwise() %>%\n",
    "      # creating column with alignment length and getting qcov\n",
    "      dplyr::mutate(aln_length = abs(ali_coord_to - ali_coord_from),\n",
    "                    qcov = aln_length/qlen) %>%\n",
    "      # query coverage must be at least 50%\n",
    "      dplyr::filter(qcov >= 0.5) %>%\n",
    "      # global sequence e-value must be at most 1e-15\n",
    "      dplyr::filter(fullseq_evalue <= 1e-10)\n",
    "                 })\n",
    "\n",
    "# saving table\n",
    "filtered_hits.tibble %>% readr::write_tsv(., '../results/homolog_groups_expansion_and_collapse/results/hmmsearch_results/hmmsearches_filtered_per_group.tsv')\n",
    "\n",
    "# getting number of hits and number of organisms hitted by each family and saving results\n",
    "filtered_hits.tibble %>% \n",
    "  ungroup() %>% \n",
    "  group_split(query_name) %>%\n",
    "  purrr::map_dfr(., ~{\n",
    "      hits = unique(.x$target_name)\n",
    "      group_tag = unique(.x$query_name)\n",
    "      organisms = .x$target_name %>% str_split('_') %>% purrr::map_chr(1)\n",
    "      organisms = unique(organisms)\n",
    "      tibble(homolog_group = group_tag, number_of_hits = length(hits), number_of_organisms = length(organisms))\n",
    "  }) %>%\n",
    "dplyr::arrange(desc(number_of_hits)) %>%\n",
    "readr::write_tsv(., '../results/homolog_groups_expansion_and_collapse/results/hmmsearch_results/hmmsearches_number_of_hits_per_group.tsv')\n",
    "\n",
    "filtered_hits.tibble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf694041-99aa-4906-bf4b-8c0d30f5ea1b",
   "metadata": {},
   "source": [
    "## Perform pairwise searches between groups and collapse them (hmmalign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7688992a-10fc-4fbb-92d9-6fd397c0ec05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import itertools\n",
    "import networkx as nx\n",
    "from Bio.SearchIO import HHsuiteIO\n",
    "from Bio import SeqIO, AlignIO\n",
    "from Bio.SeqIO import SeqRecord\n",
    "import pandas as pd\n",
    "import re\n",
    "import pyhmmer\n",
    "\n",
    "# list HMM files\n",
    "hmm_list = [(hmm.split('/')[5].replace('.hmm', ''), hmm) for hmm in glob.glob('../results/homolog_groups_expansion_and_collapse/results/homolog_groups_HMMs/*hmm')]\n",
    "\n",
    "# create directory to allocate results\n",
    "important_dirs = ['../results/homolog_groups_expansion_and_collapse/results/homolog_groups_HHMs', \n",
    "                  '../results/homolog_groups_expansion_and_collapse/results/hhalign', \n",
    "                  '../results/homolog_groups_expansion_and_collapse/results/hhalign/outfiles',\n",
    "                  '../results/homolog_groups_expansion_and_collapse/results/hhalign/tsv',\n",
    "                  '../results/homolog_groups_expansion_and_collapse/results/connected_groups',\n",
    "                  '../results/homolog_groups_expansion_and_collapse/results/connected_groups/fastas',\n",
    "                  '../results/homolog_groups_expansion_and_collapse/results/connected_groups/fastas/protein',\n",
    "                  '../results/homolog_groups_expansion_and_collapse/results/connected_groups/fastas/CDS',\n",
    "                  '../results/homolog_groups_expansion_and_collapse/results/connected_groups/tsv']\n",
    "for dir in important_dirs:\n",
    "  if not os.path.exists(dir):\n",
    "    os.mkdir(dir)\n",
    "\n",
    "# create HHM files with hhmake\n",
    "for set in hmm_list:\n",
    "  # depack variables\n",
    "  group_tag, hmm_file = set\n",
    "  # create hhm file\n",
    "  hhm_file = '../results/homolog_groups_expansion_and_collapse/results/homolog_groups_HHMs/{0}.hhm'.format(group_tag)\n",
    "  if not os.path.exists(hhm_file):\n",
    "    hhmake_cmd = 'hhmake -i ../results/homolog_groups_expansion_and_collapse/results/jackhmmer_hits_alns/{0}.msa -M first -o {1} -name {0}'.format(group_tag, hhm_file).split(' ')\n",
    "    subprocess.run(hhmake_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47af82a7-6a0e-4d71-94de-1d56fc6dcadf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create pairwise non redundant comparisons with itertools.comparisons\n",
    "## list hhm files\n",
    "hhm_list = [(hhm.split('/')[5].replace('.hhm', ''), hhm) for hhm in glob.glob('../results/homolog_groups_expansion_and_collapse/results/homolog_groups_HHMs/*hhm')]\n",
    "\n",
    "# perform pairwise alingments with hhalign.\n",
    "for pairwise_comp in itertools.combinations(hhm_list, 2):\n",
    "  # create variable for each\n",
    "  hhm_1 = pairwise_comp[0][1]\n",
    "  hhm_group_1 = pairwise_comp[0][0]\n",
    "  hhm_2 = pairwise_comp[1][1]\n",
    "  hhm_group_2 = pairwise_comp[1][0]\n",
    "  # run hhalign\n",
    "  hhalign_out = '../results/homolog_groups_expansion_and_collapse/results/hhalign/outfiles/{0}_vs_{1}.hhr'.format(hhm_group_1, hhm_group_2)\n",
    "  hhalign_tsv = '../results/homolog_groups_expansion_and_collapse/results/hhalign/tsv/{0}_vs_{1}.hhalign.tsv'.format(hhm_group_1, hhm_group_2)\n",
    "  if not os.path.exists(hhalign_out):\n",
    "    hhalign_cmd = 'hhalign -i {0} -t {1} -o {2} -atab {3}'.format(hhm_1, hhm_2, hhalign_out, hhalign_tsv).split(' ')\n",
    "    subprocess.run(hhalign_cmd)\n",
    "\n",
    "# creating dictionary with MSA sequences for each group, in order to posteriorly get alignment lengths (equal to HMM length used to filter)\n",
    "seq_msas_length_dict = {}\n",
    "for hg in glob.glob('../results/homolog_groups_expansion_and_collapse/results/homolog_groups_HMMs/*hmm'): \n",
    "    # get group name\n",
    "    hg_tag = hg.split('/')[5].replace('.hmm', '')\n",
    "    #print(hg_tag)\n",
    "    with pyhmmer.plan7.HMMFile(hg) as hmm_file:\n",
    "        hmm = next(hmm_file)\n",
    "    hmm_len = len(hmm.consensus)\n",
    "    seq_msas_length_dict.update({hg_tag: hmm_len})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b6dff298-0daa-44a2-a079-a069b6513809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create function to parse HHR file and return a pandas data frame with the relevant info\n",
    "def parse_hhsuite_hhr(hhr_file, group_1, group_2):\n",
    "  try:\n",
    "    handle_hhr = open(hhr_file, 'r')\n",
    "    hhr_hhalign = HHsuiteIO.hhsuite2_text.Hhsuite2TextParser(handle = handle_hhr)\n",
    "    hhr_hits = []\n",
    "    # storing results in pandas dataframe\n",
    "    for qresult in hhr_hhalign:\n",
    "      for hit in qresult:\n",
    "        for hsp in hit:\n",
    "          hhr_hits.append(pd.DataFrame.from_dict({'Hit ID': [hit.id], 'Query ID': [hit.query_id], 'Alignment span': [hsp.aln_span], 'e-value': [hit.evalue]}))\n",
    "    return pd.concat(hhr_hits)\n",
    "  except:\n",
    "    None\n",
    "\n",
    "# running for example file\n",
    "#example_hhr_table = parse_hhsuite_hhr(hhr_file = example_file, group_1 = '1233_LOEP01000012_1233', group_2 = '1385_LOEP01000012_1385')\n",
    "# define auxiliart function\n",
    "def get_coverage_hhr(hhr_table_row):\n",
    "  hit_hmm = hhr_table_row['Hit ID'].to_list()[0]\n",
    "  hit_hmm_length = seq_msas_length_dict[hit_hmm]\n",
    "  query_hmm = hhr_table_row['Query ID'].to_list()[0]\n",
    "  query_hmm_length = seq_msas_length_dict[query_hmm]\n",
    "  aln_span = hhr_table_row['Alignment span'].to_list()[0]\n",
    "  if hit_hmm_length >= query_hmm_length:\n",
    "    # calculate coverage based on hit_hmm_length\n",
    "    cov = aln_span/hit_hmm_length*100\n",
    "  elif hit_hmm_length < query_hmm_length:\n",
    "    cov = aln_span/query_hmm_length*100\n",
    "  # return modified hhr table\n",
    "  return hhr_table_row.assign(hit_hmm_length = hit_hmm_length, query_hmm_length = query_hmm_length, cov = cov)\n",
    "    \n",
    "#opa = example_hhr_table.assign(Hit_HMM_length = lambda x: seq_msas_length_dict[x['Hit ID'].to_list()[0]],\n",
    "#                         Query_HMM_length = lambda x: seq_msas_length_dict[x['Query ID'].to_list()[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f60e7d95-ba1c-4b6e-9fd0-564d32c22aa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('../results/homolog_groups_expansion_and_collapse/results/connected_groups/tsv/hhalign_filtered_table.tsv'):\n",
    "    hhalign_results = []\n",
    "    for hhr_file in glob.glob('../results/homolog_groups_expansion_and_collapse/results/hhalign/outfiles/*hhr'):\n",
    "      # get group tags\n",
    "      group_1_tag = hhr_file.split('/')[6].replace('.hhr', '').split('_vs_')[0]\n",
    "      group_2_tag = hhr_file.split('/')[6].replace('.hhr', '').split('_vs_')[1]\n",
    "      # getting coverage\n",
    "      hhr_parsed = parse_hhsuite_hhr(hhr_file, group_1_tag, group_2_tag)\n",
    "      try:\n",
    "        hhr_parsed_with_cov = get_coverage_hhr(hhr_parsed)\n",
    "      except:\n",
    "        hhr_parsed_with_cov = None\n",
    "      # parsing hhr file and appending result\n",
    "      hhalign_results.append(hhr_parsed_with_cov)\n",
    "    # concatenate to generate table\n",
    "    hhalign_results_table = pd.concat(hhalign_results)\n",
    "    hhalign_results_table.to_csv('../results/homolog_groups_expansion_and_collapse/results/connected_groups/tsv/hhalign_results_table.tsv', sep = '\\t')\n",
    "    # filtering table by evalue\n",
    "    hhalign_results_table_filtered = hhalign_results_table.query(\"`e-value` < 1e-5 & cov >= 50\")\n",
    "    hhalign_results_table_filtered.to_csv('../results/homolog_groups_expansion_and_collapse/results/connected_groups/tsv/hhalign_filtered_table.tsv', sep = '\\t')\n",
    "elif os.path.exists('../results/homolog_groups_expansion_and_collapse/results/connected_groups/tsv/hhalign_filtered_table.tsv'):\n",
    "    hhalign_results_table = pd.read_csv('../results/homolog_groups_expansion_and_collapse/results/connected_groups/tsv/hhalign_results_table.tsv', sep = '\\t')\n",
    "    hhalign_results_table_filtered = pd.read_csv('../results/homolog_groups_expansion_and_collapse/results/connected_groups/tsv/hhalign_filtered_table.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "72544567-92a0-4d75-ac13-089c382c4a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Hit ID</th>\n",
       "      <th>Query ID</th>\n",
       "      <th>Alignment span</th>\n",
       "      <th>e-value</th>\n",
       "      <th>hit_hmm_length</th>\n",
       "      <th>query_hmm_length</th>\n",
       "      <th>cov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>82926_Ga0207718_100100_978</td>\n",
       "      <td>41611_NZ_CP071597.1_384</td>\n",
       "      <td>343</td>\n",
       "      <td>2.300000e-126</td>\n",
       "      <td>317</td>\n",
       "      <td>330</td>\n",
       "      <td>103.939394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>85158_Ga0207719_100190_476</td>\n",
       "      <td>82877_Ga0207718_100100_929</td>\n",
       "      <td>373</td>\n",
       "      <td>5.300000e-10</td>\n",
       "      <td>398</td>\n",
       "      <td>677</td>\n",
       "      <td>55.096012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>37778_DRYJ01000053.1_300</td>\n",
       "      <td>36563_DQXS01000079.1_292</td>\n",
       "      <td>358</td>\n",
       "      <td>3.800000e-08</td>\n",
       "      <td>366</td>\n",
       "      <td>356</td>\n",
       "      <td>97.814208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>41717_NZ_CP071597.1_490</td>\n",
       "      <td>45346_LOEP01000012_1256</td>\n",
       "      <td>366</td>\n",
       "      <td>1.300000e-19</td>\n",
       "      <td>322</td>\n",
       "      <td>343</td>\n",
       "      <td>106.705539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>83636_Ga0207718_100100_1688</td>\n",
       "      <td>44950_LOEP01000012_860</td>\n",
       "      <td>163</td>\n",
       "      <td>6.300000e-09</td>\n",
       "      <td>253</td>\n",
       "      <td>227</td>\n",
       "      <td>64.426877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       Hit ID                    Query ID  \\\n",
       "0           0   82926_Ga0207718_100100_978     41611_NZ_CP071597.1_384   \n",
       "1           0   85158_Ga0207719_100190_476  82877_Ga0207718_100100_929   \n",
       "2           0     37778_DRYJ01000053.1_300    36563_DQXS01000079.1_292   \n",
       "3           0      41717_NZ_CP071597.1_490     45346_LOEP01000012_1256   \n",
       "4           0  83636_Ga0207718_100100_1688      44950_LOEP01000012_860   \n",
       "\n",
       "   Alignment span        e-value  hit_hmm_length  query_hmm_length         cov  \n",
       "0             343  2.300000e-126             317               330  103.939394  \n",
       "1             373   5.300000e-10             398               677   55.096012  \n",
       "2             358   3.800000e-08             366               356   97.814208  \n",
       "3             366   1.300000e-19             322               343  106.705539  \n",
       "4             163   6.300000e-09             253               227   64.426877  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hhalign_results_table_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fdca8d4b-2fdb-4f3f-99f1-f7e8e9cc1fc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating graph and getting conected nodes (i.e. groups of interconected groups by HMM-HMM hits)\n",
    "hmm_graph = nx.Graph()\n",
    "\n",
    "# adding node for each group in table\n",
    "hits_and_queries = []\n",
    "for x in hhalign_results_table_filtered['Hit ID'].to_list():\n",
    "  if not x in hits_and_queries:\n",
    "    hits_and_queries.append(x)\n",
    "    \n",
    "for x in hhalign_results_table_filtered['Query ID'].to_list():\n",
    "  if not x in hits_and_queries:\n",
    "    hits_and_queries.append(x)\n",
    "    \n",
    "for group in hits_and_queries:\n",
    "  # add node in graph\n",
    "  hmm_graph.add_node(group)\n",
    "\n",
    "# add edges between groups with hhalign significant HMM-HMM hits\n",
    "for matches in zip(hhalign_results_table_filtered['Hit ID'].to_list(), hhalign_results_table_filtered['Query ID'].to_list()):\n",
    "  # unpack variables\n",
    "  node_1, node_2 = matches\n",
    "  # add edge\n",
    "  hmm_graph.add_edge(node_1, node_2)\n",
    "\n",
    "# getting the connected components\n",
    "components = nx.connected_components(hmm_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "060f82a4-afee-46b2-a348-0e9b80c380b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create dictionary with all ORF protein sequences; do the same for CDS sequences\n",
    "# reading data frame with group data\n",
    "orf_annotation = pd.read_csv('../results/MEs_predicted_orfs_renamed/data/annotation_table_ORFs_renamed.tsv', \n",
    "                             sep = '\\t')\n",
    "orf_annotation['Genome ID'] = orf_annotation['Genome ID'].astype(str)\n",
    "\n",
    "# loading genome contigs\n",
    "# listing genomes\n",
    "genome_set = [(genome_file.split('/')[3].replace('ME.', '').replace('.fna', '').replace('.MAG', '').replace('.metagenome', ''),\n",
    "               genome_file) for genome_file in glob.glob('../data/mobile_elements_sequences/*')]\n",
    "\n",
    "# loading genomes with SeqIO.parse\n",
    "genomes_dict = {}\n",
    "for data_set in genome_set:\n",
    "  # unpacking variables\n",
    "  genome_tag, genome_file = data_set\n",
    "  genome = SeqIO.parse(genome_file, 'fasta')\n",
    "  # creating dictionary with sequences, descriptions and genome code\n",
    "  genome_dict = {}\n",
    "  for seq in genome:\n",
    "    genome_dict.update({seq.id: (seq.description, seq.seq)})\n",
    "  # updating dictionary\n",
    "  genomes_dict.update({genome_tag: genome_dict})\n",
    "\n",
    "# looping over DataFrame in order to get sequences\n",
    "# iterating over genomes\n",
    "# create dictionaries to store CDS and AA seqs\n",
    "CDS_seq_dict = {}\n",
    "AA_seq_dict = {}\n",
    "\n",
    "for genome_id in [x[0] for x in genome_set]:\n",
    "  # subsetting DataFrame to genomes with that ID\n",
    "  subset_annot = orf_annotation.query(\"`Genome ID` == @genome_id\")\n",
    "  # creating variable to allocate all the sequence records for this case\n",
    "  sequence_records = []\n",
    "  sequence_records_aa = []\n",
    "  # getting all sequences for that genome ID\n",
    "  for orf_id, contig, strand, start, stop in zip(subset_annot['ORF ID'], subset_annot['contig'], subset_annot['strand'], subset_annot['START'], subset_annot['STOP']):\n",
    "    # getting sequence\n",
    "    contig_id = contig.split(' ')[0]\n",
    "    if strand == '+':\n",
    "     sequence = genomes_dict[genome_id][contig_id][1][start-1:stop]\n",
    "    if strand == '-':\n",
    "     sequence = genomes_dict[genome_id][contig_id][1][stop-1:start]\n",
    "     sequence = sequence.reverse_complement()\n",
    "    # creating SeqRecord object\n",
    "    record = SeqRecord(sequence.upper(), id = orf_id, description = orf_id)\n",
    "    sequence_records.append(record)\n",
    "    # add to CDS_seq_dict\n",
    "    CDS_seq_dict.update({orf_id: record})\n",
    "    # add AA sequence to AA_seq_dict\n",
    "    sequence_aa = sequence.translate(table = 11)\n",
    "    record_aa = SeqRecord(sequence_aa.upper(), id = orf_id, description = orf_id)\n",
    "    sequence_records_aa.append(record_aa)\n",
    "    AA_seq_dict.update({orf_id: record_aa})\n",
    "\n",
    "# create dictionary between old and new ORF IDs\n",
    "orffeature2orfid_dict = {}\n",
    "orfid2orffeature_dict = {}\n",
    "for duple in zip(orf_annotation['getorf featured ID'].to_list(), orf_annotation['ORF ID'].to_list()):\n",
    "  # depack duple\n",
    "  feature_id, orf_id = duple\n",
    "  # update dictionaries\n",
    "  orffeature2orfid_dict.update({feature_id.split(' ')[0]: orf_id})\n",
    "  orfid2orffeature_dict.update({orf_id: feature_id.split(' ')[0]})\n",
    "\n",
    "# get hmmsearch results in order to retrieve hits for groups\n",
    "hmmsearch_results = pd.read_csv('../results/homolog_groups_expansion_and_collapse/results/hmmsearch_results/hmmsearches_filtered_per_group.tsv', sep = '\\t')\n",
    "hmmsearch_results_grouped = hmmsearch_results.groupby('query_name')\n",
    "# create dictionary and fill it\n",
    "hmmsearch_results_per_group_dict = {}\n",
    "for group_results in hmmsearch_results_grouped:\n",
    "  # unpack variables\n",
    "  group_tag, hmmsearch_table = group_results\n",
    "  # get hits\n",
    "  group_hits = hmmsearch_table.target_name.to_list()\n",
    "  # translate hits\n",
    "  group_hits = [orffeature2orfid_dict[hit] for hit in group_hits]\n",
    "  # update dictionary\n",
    "  hmmsearch_results_per_group_dict.update({group_tag: group_hits})\n",
    "  \n",
    "# get homologous groups and expand them with hmmsearch hits\n",
    "homolog_groups_list = [(file.split('/')[3].replace('.faa', ''),\n",
    "                        file) for file in glob.glob('../results/MEs_predicted_orfs_filtered_homologous_groups/*faa')]\n",
    "\n",
    "homolog_groups_dict = {}\n",
    "for set in homolog_groups_list:  \n",
    "  # depack variables\n",
    "  group_tag, group_file = set\n",
    "  # append records to dictionary\n",
    "  # get known records\n",
    "  group_fasta = SeqIO.parse(group_file, 'fasta')\n",
    "  group_fasta_list = [record for record in group_fasta]\n",
    "  # get expanded records by searching in hmmsearch results and retrieving sequences from ORFs dictionary\n",
    "  hitted_orfs_by_hmmsearch = hmmsearch_results_per_group_dict[group_tag]\n",
    "  hmmsearch_AA_hits = [AA_seq_dict[hit] for hit in hitted_orfs_by_hmmsearch]\n",
    "  ## backtranslate id to keep coherence in annotation # -> apparently not necessary in some cases, so performing conditional\n",
    "  for record in hmmsearch_AA_hits:\n",
    "    if record.id in list(orfid2orffeature_dict.keys()):\n",
    "      record.id = orfid2orffeature_dict[record.id]\n",
    "      record.description = ''\n",
    "      record.name = ''\n",
    "  # getting only those records not already present in group\n",
    "  hmmsearch_AA_hits = [record for record in hmmsearch_AA_hits if not record.id in [record.id for record in group_fasta_list]]\n",
    "  # append to list and update dictionary\n",
    "  group_fasta_list.extend(hmmsearch_AA_hits)\n",
    "  homolog_groups_dict.update({group_tag: group_fasta_list})\n",
    "\n",
    "# define auxiliary function to get unique set of sequences from a list of records\n",
    "def get_unique_record_set(list_of_records):\n",
    "    # create empty list to allocate unique set of records\n",
    "    unique_set_of_records = []\n",
    "    # get over records and append the if they are not in the sequence set\n",
    "    for target_record in list_of_records:\n",
    "        # get actual set of records\n",
    "        actual_set_of_records = [record.id for record in unique_set_of_records]\n",
    "        if target_record.id not in actual_set_of_records:\n",
    "            unique_set_of_records.append(target_record)\n",
    "    # return <unique_set_of_records>\n",
    "    return unique_set_of_records\n",
    "\n",
    "# collapse the collapsable groups\n",
    "collapsed_homolog_groups_list = [list(x) for x in components]\n",
    "for duple in zip(range(1, len(collapsed_homolog_groups_list)+1), collapsed_homolog_groups_list):\n",
    "  # depack variables\n",
    "  i, groups = duple\n",
    "  # create collapsed group name\n",
    "  collapsed_group_tag = 'CG_{0}'.format(i)\n",
    "  # getting sequences and appending them in same list all together\n",
    "  collapsed_group_sequences = []\n",
    "  for group in groups:\n",
    "    # retrieve sequences\n",
    "    group_seqs = homolog_groups_dict[group]\n",
    "    # append to <collapsed_group_sequences>\n",
    "    collapsed_group_sequences.extend(group_seqs)\n",
    "    # pop the groups from <homolog_groups_dict>\n",
    "    homolog_groups_dict.pop(group)\n",
    "  # get unique set of sequences\n",
    "  collapsed_group_sequences = get_unique_record_set(list_of_records = collapsed_group_sequences)\n",
    "  # update with collapsed group sequences\n",
    "  homolog_groups_dict.update({collapsed_group_tag: collapsed_group_sequences})\n",
    "\n",
    "# translate names of sequences\n",
    "for group in list(homolog_groups_dict.keys()):\n",
    "  # get sequences and rename them\n",
    "  sequences = homolog_groups_dict[group]\n",
    "  for seq in sequences:\n",
    "    # change seq.id and seq.description\n",
    "    seq_id = seq.id\n",
    "    #seq.id = orffeature2orfid_dict[seq_id]\n",
    "    seq.description = ''\n",
    "  # set the sequences in the dictionary\n",
    "  homolog_groups_dict[group] = sequences\n",
    "  \n",
    "# create table with groups and sequences\n",
    "# creating lists to allocate the data\n",
    "group_tags = list(homolog_groups_dict.keys())\n",
    "files = []\n",
    "for tag in group_tags:\n",
    "  # if isnt collapsed group, then add the word '_expanded'\n",
    "  if re.match('^CG_', tag):\n",
    "    files.append('../results/homolog_groups_expansion_and_collapse/results/connected_groups/fastas/protein/{0}.faa'.format(tag))\n",
    "  else:\n",
    "    files.append('../results/homolog_groups_expansion_and_collapse/results/connected_groups/fastas/protein/{0}_expanded.faa'.format(tag))\n",
    "\n",
    "# getting sequence names and collapsing them in a line for the table\n",
    "sequence_names = ['; '.join([seq.id for seq in records]) for records in list(homolog_groups_dict.values())]\n",
    "\n",
    "# creating a pandas DataFrame\n",
    "# creating dictionary to create a DataFrame object later\n",
    "homolog_groups_data = {'Group tag': group_tags, 'File': files, 'Sequence names': sequence_names, 'Number of sequences': [len(x.split('; ')) for x in sequence_names]}\n",
    "homolog_groups_table = pd.DataFrame.from_dict(homolog_groups_data, orient='columns')\n",
    "\n",
    "# order table based on number of sequences\n",
    "homolog_groups_table = homolog_groups_table.sort_values(by = ['Number of sequences'], axis = 0, ascending = False)\n",
    "\n",
    "# export table\n",
    "homolog_groups_table.to_csv('../results/homolog_groups_expansion_and_collapse/results/connected_groups/tsv/expanded_homologs_groups.tsv', sep = '\\t')\n",
    "\n",
    "# save FASTAs\n",
    "for set in homolog_groups_table.groupby('Group tag'):\n",
    "  # depack variables\n",
    "  group_tag, row = set\n",
    "  # get export file\n",
    "  fasta_output = row.File.to_list()[0]\n",
    "  # get sequences\n",
    "  records = homolog_groups_dict[group_tag]\n",
    "  # save records in FASTA file\n",
    "  if not os.path.exists(fasta_output):\n",
    "    with open(fasta_output, 'w') as output_handle:\n",
    "        SeqIO.write(records, output_handle, 'fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed75be3-8d75-4d3c-8b24-1ac106c9c657",
   "metadata": {},
   "source": [
    "## Filtering for target PCGs, MAGs and metagenomes\n",
    "Going to take into account only PCGs, MAGs and metagenomes of at least 20kbps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d2cf1896-b43a-4ec1-bdeb-0774fbdaf326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating directory to allocate results\n",
    "target_dirs = ['../results/homolog_groups_expansion_and_collapse/results/connected_groups_filtered',\n",
    "               '../results/homolog_groups_expansion_and_collapse/results/connected_groups_filtered/fastas',\n",
    "               '../results/homolog_groups_expansion_and_collapse/results/connected_groups_filtered/fastas/protein',\n",
    "               '../results/homolog_groups_expansion_and_collapse/results/connected_groups_filtered/trees',\n",
    "               '../results/homolog_groups_expansion_and_collapse/results/connected_groups_filtered/plots',\n",
    "               '../results/homolog_groups_expansion_and_collapse/results/connected_groups_filtered/tsv']\n",
    "\n",
    "for dir in target_dirs:\n",
    "    create_dir(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1f0ab49e-15d9-4441-940c-5c09db56b125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting all mobile sequences files and getting their length, then filtering to get target IDs\n",
    "# create a dictionary between Genome IDs and taxonomy\n",
    "genome2taxonomy_dict = {}\n",
    "for index, row in genome2taxonomy_table.iterrows():\n",
    "    # get genome and taxonomy\n",
    "    genomeid = row['Genome_id'].replace('GCA_', '')\n",
    "    taxonomy = row['Taxonomy']\n",
    "    genome2taxonomy_dict.update({genomeid: taxonomy})\n",
    "\n",
    "# create list to allocate rows with info, and later collapse into table\n",
    "mobile_element_lengths_rows = []\n",
    "for fasta_file in glob.glob('../data/mobile_elements_sequences/*fna'):\n",
    "    #print(fasta_file)\n",
    "    # getting group tag\n",
    "    group_tag = fasta_file.split('/')[3].replace('ME.', '').replace('.MAG', '').replace('.metagenome', '').replace('.fna', '')\n",
    "    # get a version with prefixes to sample ORFs\n",
    "    me_orf_file = fasta_file.split('/')[3].replace('.fna', '.predicted_orfs.faa')\n",
    "    #print(group_tag)\n",
    "    # getting length in bp\n",
    "    group_seq_lengths = [len(record.seq) for record in SeqIO.parse(fasta_file, 'fasta')]\n",
    "    # append row\n",
    "    mobile_element_lengths_rows.append(pd.DataFrame.from_dict({'Group tag': [group_tag], 'Taxonomy': [genome2taxonomy_dict[group_tag]], 'ME_file': [me_orf_file], 'Total length': [sum(group_seq_lengths)]}))\n",
    "\n",
    "# concatenate into a table\n",
    "mobile_element_lengths_table = pd.concat(mobile_element_lengths_rows)\n",
    "\n",
    "# filtering table\n",
    "mobile_element_lengths_table_filtered = mobile_element_lengths_table.query(\"`Total length` >= 20000\")\n",
    "\n",
    "# getting sequences from this organisms\n",
    "target_organisms_ORFs = []\n",
    "for index, row in mobile_element_lengths_table_filtered.iterrows():\n",
    "    # get group tag\n",
    "    group_tag = row['Group tag']\n",
    "    # create ME orf file\n",
    "    me_file = row['ME_file']\n",
    "    me_file_full = '../results/MEs_predicted_orfs/{0}'.format(me_file)\n",
    "    # get the sequences and store them\n",
    "    seq_ids = [record.id for record in SeqIO.parse(me_file_full, 'fasta')]\n",
    "    for seq_id in seq_ids:\n",
    "        target_organisms_ORFs.append(seq_id)\n",
    "\n",
    "# subsampling FASTA files of connected groups and saving sequences belonging to target groups\n",
    "for fasta_file in glob.glob('../results/homolog_groups_expansion_and_collapse/results/connected_groups/fastas/protein/*faa'):\n",
    "    # get new group direction\n",
    "    new_group_fasta_file = fasta_file.replace('connected_groups', 'connected_groups_filtered')\n",
    "    # get sequences\n",
    "    group_seqs = [record for record in SeqIO.parse(fasta_file, 'fasta')]\n",
    "    # filter sequences to get only those of target organisms\n",
    "    filtered_group_seqs = [record for record in group_seqs if record.id in target_organisms_ORFs]\n",
    "    # save in fasta file\n",
    "    if not os.path.exists(new_group_fasta_file):\n",
    "        with open(new_group_fasta_file, 'w') as handle_fasta:\n",
    "            SeqIO.write(filtered_group_seqs, handle_fasta, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "52100c0b-d148-48de-a1f4-a576ff6fc743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# saving target organisms table\n",
    "mobile_element_lengths_table_filtered.to_csv('../results/target_organisms.tsv', sep ='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "008257c0-64ba-4417-a13d-70bd2551e0dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group tag</th>\n",
       "      <th>Taxonomy</th>\n",
       "      <th>ME_file</th>\n",
       "      <th>Total length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ga0207733_100382</td>\n",
       "      <td>ga0207733_100382</td>\n",
       "      <td>ME.ga0207733_100382.metagenome.predicted_orfs.faa</td>\n",
       "      <td>30902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000830315.1</td>\n",
       "      <td>Nanoarchaeota_GW2011-AR20_sp000830315</td>\n",
       "      <td>ME.000830315.1.MAG.predicted_orfs.faa</td>\n",
       "      <td>829411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ga0222658_1000332</td>\n",
       "      <td>ga0222658_1000332</td>\n",
       "      <td>ME.ga0222658_1000332.metagenome.predicted_orfs...</td>\n",
       "      <td>26142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ga0116200_10000074</td>\n",
       "      <td>ga0116200_10000074</td>\n",
       "      <td>ME.ga0116200_10000074.metagenome.predicted_orf...</td>\n",
       "      <td>22669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ga0172379_10001592</td>\n",
       "      <td>ga0172379_10001592</td>\n",
       "      <td>ME.ga0172379_10001592.metagenome.predicted_orf...</td>\n",
       "      <td>44548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003644925.1</td>\n",
       "      <td>Fermentibacterota_Aegiribacteria_sp003644925</td>\n",
       "      <td>ME.003644925.1.MAG.predicted_orfs.faa</td>\n",
       "      <td>40684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60847.21</td>\n",
       "      <td>Halogeometricum_borinquense_strain_wsp4</td>\n",
       "      <td>ME.60847.21.predicted_orfs.faa</td>\n",
       "      <td>89772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ga0075122_10000827</td>\n",
       "      <td>ga0075122_10000827</td>\n",
       "      <td>ME.ga0075122_10000827.metagenome.predicted_orf...</td>\n",
       "      <td>23359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ga0172377_10000119</td>\n",
       "      <td>ga0172377_10000119</td>\n",
       "      <td>ME.ga0172377_10000119.metagenome.predicted_orf...</td>\n",
       "      <td>65850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ga0222667_1000160</td>\n",
       "      <td>ga0222667_1000160</td>\n",
       "      <td>ME.ga0222667_1000160.metagenome.predicted_orfs...</td>\n",
       "      <td>38591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ga0065719_100268</td>\n",
       "      <td>ga0065719_100268</td>\n",
       "      <td>ME.ga0065719_100268.metagenome.predicted_orfs.faa</td>\n",
       "      <td>26098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ga0207718_100100</td>\n",
       "      <td>ga0207718_100100</td>\n",
       "      <td>ME.ga0207718_100100.metagenome.predicted_orfs.faa</td>\n",
       "      <td>108523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>011042275.1</td>\n",
       "      <td>Altarchaeota_QMZG01_sp003663045</td>\n",
       "      <td>ME.011042275.1.MAG.predicted_orfs.faa</td>\n",
       "      <td>22669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2496101.3</td>\n",
       "      <td>Haloterrigena_sp_SYSU_A121-1</td>\n",
       "      <td>ME.2496101.3.predicted_orfs.faa</td>\n",
       "      <td>98810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>017357405.1</td>\n",
       "      <td>Halovivax_sp_KZCA124</td>\n",
       "      <td>ME.017357405.1.predicted_orfs.faa</td>\n",
       "      <td>94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ga0075122_10000851</td>\n",
       "      <td>ga0075122_10000851</td>\n",
       "      <td>ME.ga0075122_10000851.metagenome.predicted_orf...</td>\n",
       "      <td>23010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001563915.1</td>\n",
       "      <td>Nanohaloarchaeota_B1-Br10-U2g21_sp001563915</td>\n",
       "      <td>ME.001563915.1.MAG.predicted_orfs.faa</td>\n",
       "      <td>42545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ga0164313_10000250</td>\n",
       "      <td>ga0164313_10000250</td>\n",
       "      <td>ME.ga0164313_10000250.metagenome.predicted_orf...</td>\n",
       "      <td>40684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ga0207715_100102</td>\n",
       "      <td>ga0207715_100102</td>\n",
       "      <td>ME.ga0207715_100102.metagenome.predicted_orfs.faa</td>\n",
       "      <td>77674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ga0075120_10000694</td>\n",
       "      <td>ga0075120_10000694</td>\n",
       "      <td>ME.ga0075120_10000694.metagenome.predicted_orf...</td>\n",
       "      <td>27816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ga0172379_10000243</td>\n",
       "      <td>ga0172379_10000243</td>\n",
       "      <td>ME.ga0172379_10000243.metagenome.predicted_orf...</td>\n",
       "      <td>148427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ga0207719_100190</td>\n",
       "      <td>ga0207719_100190</td>\n",
       "      <td>ME.ga0207719_100190.metagenome.predicted_orfs.faa</td>\n",
       "      <td>48632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>222984.5</td>\n",
       "      <td>Natrinema_altunense_strain_AJ2</td>\n",
       "      <td>ME.222984.5.predicted_orfs.faa</td>\n",
       "      <td>94988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ga0078972_1006503</td>\n",
       "      <td>ga0078972_1006503</td>\n",
       "      <td>ME.ga0078972_1006503.metagenome.predicted_orfs...</td>\n",
       "      <td>27587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ga0208375_1000150</td>\n",
       "      <td>ga0208375_1000150</td>\n",
       "      <td>ME.ga0208375_1000150.metagenome.predicted_orfs...</td>\n",
       "      <td>109186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ga0075122_10000557</td>\n",
       "      <td>ga0075122_10000557</td>\n",
       "      <td>ME.ga0075122_10000557.metagenome.predicted_orf...</td>\n",
       "      <td>29169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2743089.3</td>\n",
       "      <td>Halobonum_sp_NJ-3-1</td>\n",
       "      <td>ME.2743089.3.predicted_orfs.faa</td>\n",
       "      <td>172009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jgi12330j12834_1000008</td>\n",
       "      <td>jgi12330j12834_1000008</td>\n",
       "      <td>ME.jgi12330j12834_1000008.metagenome.predicted...</td>\n",
       "      <td>97919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1526048.3</td>\n",
       "      <td>Haloferax_sp_Q22</td>\n",
       "      <td>ME.1526048.3.predicted_orfs.faa</td>\n",
       "      <td>56511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>926690.3</td>\n",
       "      <td>Haloplanus_natans_DSM_17983</td>\n",
       "      <td>ME.926690.3.predicted_orfs.faa</td>\n",
       "      <td>113161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>012026795.1</td>\n",
       "      <td>Halobacteriota_Methanoperedens_sp012026795</td>\n",
       "      <td>ME.012026795.1.MAG.predicted_orfs.faa</td>\n",
       "      <td>52337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>011380245.1</td>\n",
       "      <td>Thermoproteota_DSZF01_sp011372955</td>\n",
       "      <td>ME.011380245.1.MAG.predicted_orfs.faa</td>\n",
       "      <td>26098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Group tag                                      Taxonomy  \\\n",
       "0        ga0207733_100382                              ga0207733_100382   \n",
       "0             000830315.1         Nanoarchaeota_GW2011-AR20_sp000830315   \n",
       "0       ga0222658_1000332                             ga0222658_1000332   \n",
       "0      ga0116200_10000074                            ga0116200_10000074   \n",
       "0      ga0172379_10001592                            ga0172379_10001592   \n",
       "0             003644925.1  Fermentibacterota_Aegiribacteria_sp003644925   \n",
       "0                60847.21       Halogeometricum_borinquense_strain_wsp4   \n",
       "0      ga0075122_10000827                            ga0075122_10000827   \n",
       "0      ga0172377_10000119                            ga0172377_10000119   \n",
       "0       ga0222667_1000160                             ga0222667_1000160   \n",
       "0        ga0065719_100268                              ga0065719_100268   \n",
       "0        ga0207718_100100                              ga0207718_100100   \n",
       "0             011042275.1               Altarchaeota_QMZG01_sp003663045   \n",
       "0               2496101.3                  Haloterrigena_sp_SYSU_A121-1   \n",
       "0             017357405.1                          Halovivax_sp_KZCA124   \n",
       "0      ga0075122_10000851                            ga0075122_10000851   \n",
       "0             001563915.1   Nanohaloarchaeota_B1-Br10-U2g21_sp001563915   \n",
       "0      ga0164313_10000250                            ga0164313_10000250   \n",
       "0        ga0207715_100102                              ga0207715_100102   \n",
       "0      ga0075120_10000694                            ga0075120_10000694   \n",
       "0      ga0172379_10000243                            ga0172379_10000243   \n",
       "0        ga0207719_100190                              ga0207719_100190   \n",
       "0                222984.5                Natrinema_altunense_strain_AJ2   \n",
       "0       ga0078972_1006503                             ga0078972_1006503   \n",
       "0       ga0208375_1000150                             ga0208375_1000150   \n",
       "0      ga0075122_10000557                            ga0075122_10000557   \n",
       "0               2743089.3                           Halobonum_sp_NJ-3-1   \n",
       "0  jgi12330j12834_1000008                        jgi12330j12834_1000008   \n",
       "0               1526048.3                              Haloferax_sp_Q22   \n",
       "0                926690.3                   Haloplanus_natans_DSM_17983   \n",
       "0             012026795.1    Halobacteriota_Methanoperedens_sp012026795   \n",
       "0             011380245.1             Thermoproteota_DSZF01_sp011372955   \n",
       "\n",
       "                                             ME_file  Total length  \n",
       "0  ME.ga0207733_100382.metagenome.predicted_orfs.faa         30902  \n",
       "0              ME.000830315.1.MAG.predicted_orfs.faa        829411  \n",
       "0  ME.ga0222658_1000332.metagenome.predicted_orfs...         26142  \n",
       "0  ME.ga0116200_10000074.metagenome.predicted_orf...         22669  \n",
       "0  ME.ga0172379_10001592.metagenome.predicted_orf...         44548  \n",
       "0              ME.003644925.1.MAG.predicted_orfs.faa         40684  \n",
       "0                     ME.60847.21.predicted_orfs.faa         89772  \n",
       "0  ME.ga0075122_10000827.metagenome.predicted_orf...         23359  \n",
       "0  ME.ga0172377_10000119.metagenome.predicted_orf...         65850  \n",
       "0  ME.ga0222667_1000160.metagenome.predicted_orfs...         38591  \n",
       "0  ME.ga0065719_100268.metagenome.predicted_orfs.faa         26098  \n",
       "0  ME.ga0207718_100100.metagenome.predicted_orfs.faa        108523  \n",
       "0              ME.011042275.1.MAG.predicted_orfs.faa         22669  \n",
       "0                    ME.2496101.3.predicted_orfs.faa         98810  \n",
       "0                  ME.017357405.1.predicted_orfs.faa         94500  \n",
       "0  ME.ga0075122_10000851.metagenome.predicted_orf...         23010  \n",
       "0              ME.001563915.1.MAG.predicted_orfs.faa         42545  \n",
       "0  ME.ga0164313_10000250.metagenome.predicted_orf...         40684  \n",
       "0  ME.ga0207715_100102.metagenome.predicted_orfs.faa         77674  \n",
       "0  ME.ga0075120_10000694.metagenome.predicted_orf...         27816  \n",
       "0  ME.ga0172379_10000243.metagenome.predicted_orf...        148427  \n",
       "0  ME.ga0207719_100190.metagenome.predicted_orfs.faa         48632  \n",
       "0                     ME.222984.5.predicted_orfs.faa         94988  \n",
       "0  ME.ga0078972_1006503.metagenome.predicted_orfs...         27587  \n",
       "0  ME.ga0208375_1000150.metagenome.predicted_orfs...        109186  \n",
       "0  ME.ga0075122_10000557.metagenome.predicted_orf...         29169  \n",
       "0                    ME.2743089.3.predicted_orfs.faa        172009  \n",
       "0  ME.jgi12330j12834_1000008.metagenome.predicted...         97919  \n",
       "0                    ME.1526048.3.predicted_orfs.faa         56511  \n",
       "0                     ME.926690.3.predicted_orfs.faa        113161  \n",
       "0              ME.012026795.1.MAG.predicted_orfs.faa         52337  \n",
       "0              ME.011380245.1.MAG.predicted_orfs.faa         26098  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_element_lengths_table_filtered"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
